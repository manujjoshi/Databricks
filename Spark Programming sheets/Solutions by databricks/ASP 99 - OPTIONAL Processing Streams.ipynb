{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75dd20bd-aa3e-4e1c-9d97-484e99477408"}}},{"cell_type":"markdown","source":["# Activity by Traffic Lab\nProcess streaming data to display total active users by traffic source.\n\n##### Objectives\n1. Read data stream\n2. Get active users by traffic source\n3. Execute query with display() and plot results\n4. Execute the same streaming query with DataStreamWriter\n5. View results being updated in the query table\n6. List and stop all active streams\n\n##### Classes\n- <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=datastreamreader#pyspark.sql.streaming.DataStreamReader\" target=\"_blank\">DataStreamReader</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=datastreamwriter#pyspark.sql.streaming.DataStreamWriter\" target=\"_blank\">DataStreamWriter</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=streamingquery#pyspark.sql.streaming.StreamingQuery\" target=\"_blank\">StreamingQuery</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=streamingquerymanager#pyspark.sql.streaming.StreamingQueryManager\" target=\"_blank\">StreamingQueryManager</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d4c7479-069a-4d16-b647-ca34a36eecbf"}}},{"cell_type":"markdown","source":["### Setup\nRun the cells below to generate data and create the **`schema`** string needed for this lab."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"472894d9-752f-4c50-a7eb-5b18188300da"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a9bc62c-7e83-4465-a5c5-71aaa9db1ea3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["schema = \"device STRING, ecommerce STRUCT<purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT>, event_name STRING, event_previous_timestamp BIGINT, event_timestamp BIGINT, geo STRUCT<city: STRING, state: STRING>, items ARRAY<STRUCT<coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT>>, traffic_source STRING, user_first_touch_timestamp BIGINT, user_id STRING\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b94f4d8d-2dab-4b9f-b5e1-6c9fb0820e2c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 1. Read data stream\n- Use schema stored in **`schema`**\n- Set to process 1 file per trigger\n- Read from parquet with filepath stored in **`eventsPath`**\n\nAssign the resulting DataFrame to **`df`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8b6755e-b634-4b00-b814-146a316488a3"}}},{"cell_type":"code","source":["# ANSWER\ndf = (spark\n      .readStream\n      .schema(schema)\n      .option(\"maxFilesPerTrigger\", 1)\n      .parquet(eventsPath)\n     )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5de20dca-9c2e-4aa6-995a-859aed608c1d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2e46a96-38b5-4ac5-a8ac-09961eb0663a"}}},{"cell_type":"code","source":["assert df.isStreaming\nassert df.columns == [\"device\", \"ecommerce\", \"event_name\", \"event_previous_timestamp\", \"event_timestamp\", \"geo\", \"items\", \"traffic_source\", \"user_first_touch_timestamp\", \"user_id\"]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"930f75cd-0ab6-4d46-bae3-b672898d8952"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Get active users by traffic source\n- Set default shuffle partitions to number of cores on your cluster (not required, but runs faster)\n- Group by **`traffic_source`**\n  - Aggregate the approximate count of distinct users and alias with \"active_users\"\n- Sort by **`traffic_source`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"654ae39f-127f-4591-b7e5-2279313804cc"}}},{"cell_type":"code","source":["# ANSWER\nfrom pyspark.sql.functions import col, approx_count_distinct, count\n\nspark.conf.set(\"spark.sql.shuffle.partitions\", spark.sparkContext.defaultParallelism)\n\ntrafficDF = (df\n             .groupBy(\"traffic_source\")\n             .agg(approx_count_distinct(\"user_id\").alias(\"active_users\"))\n             .sort(\"traffic_source\")\n            )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6091be94-73d2-4897-b82e-7459abe9f66c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c40c7f91-acaa-4f7d-acce-b3195d97b7af"}}},{"cell_type":"code","source":["assert str(trafficDF.schema) == \"StructType(List(StructField(traffic_source,StringType,true),StructField(active_users,LongType,false)))\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb225ba6-fd09-4ed7-ae92-656df48c2d23"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3. Execute query with display() and plot results\n- Execute results for **`trafficDF`** using display()\n- Plot the streaming query results as a bar graph"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c41e2bdb-53a8-405a-acd6-b77aeae0ee06"}}},{"cell_type":"code","source":["# ANSWER\ndisplay(trafficDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c380af2-f4d9-4dc8-8d31-f231617884cb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**\n- You bar chart should plot `traffic_source` on the x-axis and `active_users` on the y-axis\n- The top three traffic sources in descending order should be `google`, `facebook`, and `instagram`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6346c84e-d0ce-4741-bce9-19e359a7cae9"}}},{"cell_type":"markdown","source":["### 4. Execute the same streaming query with DataStreamWriter\n- Name the query \"active_users_by_traffic\"\n- Set to \"memory\" format and \"complete\" output mode\n- Set a trigger interval of 1 second"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"404bc56c-63d4-4766-ba85-d0a2fd3fb165"}}},{"cell_type":"code","source":["# ANSWER\ntrafficQuery = (trafficDF\n                .writeStream\n                .queryName(\"active_users_by_traffic_p\")\n                .format(\"memory\")\n                .outputMode(\"complete\")\n                .trigger(processingTime=\"1 second\")\n                .start()\n               )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30e98141-9a67-4d14-9a99-700fa3c8a470"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e74023a8-538d-454e-a865-d104488bc274"}}},{"cell_type":"code","source":["untilStreamIsReady(\"active_users_by_traffic\")\nassert trafficQuery.isActive\nassert \"active_users_by_traffic\" in trafficQuery.name\nassert trafficQuery.lastProgress[\"sink\"][\"description\"] == \"MemorySink\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1146537c-a227-4935-baa9-63d234f1f4ee"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 5. View results being updated in the query table\nRun a query in a SQL cell to display the results from the **`active_users_by_traffic`** table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae76979b-e64c-4e4a-98f4-fb2929bb1975"}}},{"cell_type":"code","source":["%sql\n-- ANSWER\nSELECT * FROM active_users_by_traffic_p"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34c54d4c-c1a6-43fb-a4c4-1be76249020c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**  \nYour query should eventually result in the following values.\n\n|traffic_source|active_users|\n|---|---|\n|direct|438886|\n|email|281525|\n|facebook|956769|\n|google|1781961|\n|instagram|530050|\n|youtube|253321|"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b86b2a20-864d-4104-80aa-e7c3c0b51da8"}}},{"cell_type":"markdown","source":["### 6. List and stop all active streams\n- Use SparkSession to get list of all active streams\n- Iterate over the list and stop each query"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5de85c91-d4d1-4374-9e18-17684d0ce518"}}},{"cell_type":"code","source":["# ANSWER\nfor s in spark.streams.active:\n    print(s.name)\n    s.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07a0f94b-0187-4f89-b58f-4868dd285ea8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a66c098e-0e58-484e-9383-7055adbf1ecb"}}},{"cell_type":"code","source":["assert not trafficQuery.isActive"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b3f573c-9b3b-4b62-b5f3-fd60f8d81d5a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup\nRun the cell below to clean up resources."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c46fae7e-5062-4b46-97e0-f8529d897322"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d83c071c-6a14-41d1-8ee5-3157e766bd2b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fa1a10e-329a-46c8-b1ca-209490e0bb9c"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 99 - OPTIONAL Processing Streams","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2331746562399089}},"nbformat":4,"nbformat_minor":0}
