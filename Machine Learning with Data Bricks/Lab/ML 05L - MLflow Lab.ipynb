{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"227efa35-7395-472b-85ee-6df0babddfab"}}},{"cell_type":"markdown","source":["# MLflow Lab\n\nIn this lab we will explore the path to moving models to production with MLflow using the following steps:\n\n1. Load in Airbnb dataset, and save both training dataset and test dataset as Delta tables\n2. Train an MLlib linear regression model using all the listing features and tracking parameters, metrics artifacts and Delta table version to MLflow\n3. Register this initial model and move it to staging using MLflow Model Registry\n4. Add a new column, **`log_price`** to both our train and test table and update the corresponding Delta tables\n5. Train a second MLlib linear regression model, this time using **`log_price`** as our target and training on all features, tracking to MLflow \n6. Compare the performance of the different runs by looking at the underlying data versions for both models\n7. Move the better performing model to production in MLflow model registry\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you:<br>\n- **Create Delta tables**\n- **Track your MLlib model and Delta table version using MLflow**\n- **Use MLflow model registry to version your models**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b256ffad-21cc-4d50-b468-21ed130c0826"}}},{"cell_type":"code","source":["%pip install mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77773523-be66-4fcd-9e22-2fb446ad9495"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting mlflow\n  Using cached mlflow-1.28.0-py3-none-any.whl (17.0 MB)\nCollecting cloudpickle&lt;3\n  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\nCollecting databricks-cli&lt;1,&gt;=0.8.7\n  Using cached databricks_cli-0.17.2-py3-none-any.whl\nCollecting click&lt;9,&gt;=7.0\n  Using cached click-8.1.3-py3-none-any.whl (96 kB)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nCollecting docker&lt;6,&gt;=4.0.0\n  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting sqlparse&lt;1,&gt;=0.4.0\n  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nCollecting prometheus-flask-exporter&lt;1\n  Using cached prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\nCollecting pyyaml&lt;7,&gt;=5.1\n  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\nCollecting alembic&lt;2\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\nCollecting gitpython&lt;4,&gt;=2.1.0\n  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nCollecting sqlalchemy&lt;2,&gt;=1.4.0\n  Using cached SQLAlchemy-1.4.40-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nCollecting gunicorn&lt;21\n  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0\n  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nCollecting Flask&lt;3\n  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\nCollecting querystring-parser&lt;2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nCollecting importlib-resources\n  Using cached importlib_resources-5.9.0-py3-none-any.whl (33 kB)\nCollecting Mako\n  Using cached Mako-1.2.1-py3-none-any.whl (78 kB)\nCollecting oauthlib&gt;=3.1.0\n  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nCollecting pyjwt&gt;=1.7.0\n  Using cached PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting tabulate&gt;=0.7.7\n  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting websocket-client&gt;=0.32.0\n  Using cached websocket_client-1.4.0-py3-none-any.whl (54 kB)\nCollecting itsdangerous&gt;=2.0\n  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting Jinja2&gt;=3.0\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting Werkzeug&gt;=2.2.2\n  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nCollecting gitdb&lt;5,&gt;=4.0.1\n  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\nCollecting smmap&lt;6,&gt;=3.0.1\n  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nCollecting zipp&gt;=0.5\n  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&gt;=3.0-&gt;Flask&lt;3-&gt;mlflow) (2.0.1)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22-&gt;mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2-&gt;mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter&lt;1-&gt;mlflow) (0.10.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (4.0.0)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\nCollecting MarkupSafe&gt;=2.0\n  Using cached MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, smmap, Jinja2, itsdangerous, importlib-metadata, greenlet, click, websocket-client, tabulate, sqlalchemy, pyjwt, oauthlib, Mako, importlib-resources, gitdb, Flask, sqlparse, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, cloudpickle, alembic, mlflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-09de0c3b-1631-4b62-80cc-a85e82620db2\n    Can&#39;t uninstall &#39;MarkupSafe&#39;. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-09de0c3b-1631-4b62-80cc-a85e82620db2\n    Can&#39;t uninstall &#39;Jinja2&#39;. No files were found to uninstall.\nSuccessfully installed Flask-2.2.2 Jinja2-3.1.2 Mako-1.2.1 MarkupSafe-2.1.1 Werkzeug-2.2.2 alembic-1.8.1 click-8.1.3 cloudpickle-2.1.0 databricks-cli-0.17.2 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 greenlet-1.1.3 gunicorn-20.1.0 importlib-metadata-4.12.0 importlib-resources-5.9.0 itsdangerous-2.1.2 mlflow-1.28.0 oauthlib-3.2.0 prometheus-flask-exporter-0.20.3 pyjwt-2.4.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 sqlalchemy-1.4.40 sqlparse-0.4.2 tabulate-0.8.10 websocket-client-1.4.0 zipp-3.8.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting mlflow\n  Using cached mlflow-1.28.0-py3-none-any.whl (17.0 MB)\nCollecting cloudpickle&lt;3\n  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\nCollecting databricks-cli&lt;1,&gt;=0.8.7\n  Using cached databricks_cli-0.17.2-py3-none-any.whl\nCollecting click&lt;9,&gt;=7.0\n  Using cached click-8.1.3-py3-none-any.whl (96 kB)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nCollecting docker&lt;6,&gt;=4.0.0\n  Using cached docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting sqlparse&lt;1,&gt;=0.4.0\n  Using cached sqlparse-0.4.2-py3-none-any.whl (42 kB)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nCollecting prometheus-flask-exporter&lt;1\n  Using cached prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\nCollecting pyyaml&lt;7,&gt;=5.1\n  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\nCollecting alembic&lt;2\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\nCollecting gitpython&lt;4,&gt;=2.1.0\n  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nCollecting sqlalchemy&lt;2,&gt;=1.4.0\n  Using cached SQLAlchemy-1.4.40-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nCollecting gunicorn&lt;21\n  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0\n  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nCollecting Flask&lt;3\n  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\nCollecting querystring-parser&lt;2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nCollecting importlib-resources\n  Using cached importlib_resources-5.9.0-py3-none-any.whl (33 kB)\nCollecting Mako\n  Using cached Mako-1.2.1-py3-none-any.whl (78 kB)\nCollecting oauthlib&gt;=3.1.0\n  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nCollecting pyjwt&gt;=1.7.0\n  Using cached PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting tabulate&gt;=0.7.7\n  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting websocket-client&gt;=0.32.0\n  Using cached websocket_client-1.4.0-py3-none-any.whl (54 kB)\nCollecting itsdangerous&gt;=2.0\n  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting Jinja2&gt;=3.0\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting Werkzeug&gt;=2.2.2\n  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nCollecting gitdb&lt;5,&gt;=4.0.1\n  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\nCollecting smmap&lt;6,&gt;=3.0.1\n  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nCollecting zipp&gt;=0.5\n  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&gt;=3.0-&gt;Flask&lt;3-&gt;mlflow) (2.0.1)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22-&gt;mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2-&gt;mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter&lt;1-&gt;mlflow) (0.10.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (4.0.0)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\nCollecting MarkupSafe&gt;=2.0\n  Using cached MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, smmap, Jinja2, itsdangerous, importlib-metadata, greenlet, click, websocket-client, tabulate, sqlalchemy, pyjwt, oauthlib, Mako, importlib-resources, gitdb, Flask, sqlparse, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, cloudpickle, alembic, mlflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-09de0c3b-1631-4b62-80cc-a85e82620db2\n    Can&#39;t uninstall &#39;MarkupSafe&#39;. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-09de0c3b-1631-4b62-80cc-a85e82620db2\n    Can&#39;t uninstall &#39;Jinja2&#39;. No files were found to uninstall.\nSuccessfully installed Flask-2.2.2 Jinja2-3.1.2 Mako-1.2.1 MarkupSafe-2.1.1 Werkzeug-2.2.2 alembic-1.8.1 click-8.1.3 cloudpickle-2.1.0 databricks-cli-0.17.2 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 greenlet-1.1.3 gunicorn-20.1.0 importlib-metadata-4.12.0 importlib-resources-5.9.0 itsdangerous-2.1.2 mlflow-1.28.0 oauthlib-3.2.0 prometheus-flask-exporter-0.20.3 pyjwt-2.4.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 sqlalchemy-1.4.40 sqlparse-0.4.2 tabulate-0.8.10 websocket-client-1.4.0 zipp-3.8.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcdb944b-0acb-48ce-954e-dcc1959a6fb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Defining courseware-specific utility methods...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Defining courseware-specific utility methods..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">The source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/scalable-machine-learning-with-apache-spark/v01/\n\nYour dataset directory is\ndbfs:/user/manujkumar.joshi@celebaltech.com/dbacademy/machine_learning/datasets\n\nSkipping install of existing dataset.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/scalable-machine-learning-with-apache-spark/v01/\n\nYour dataset directory is\ndbfs:/user/manujkumar.joshi@celebaltech.com/dbacademy/machine_learning/datasets\n\nSkipping install of existing dataset.\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###  Step 1. Creating Delta Tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ceead040-4e0d-43c4-901d-da0720b2c7b4"}}},{"cell_type":"markdown","source":["#### Data versioning is an advantage of using Delta Lake, which preserves previous versions of datasets so that you can restore later.\n\nLet's split our dataset into train and test datasets, and writing them out in Delta format. You can read more at the Delta Lake <a href=\"https://docs.delta.io/latest/index.html\" target=\"_blank\">documentation</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1556e81-a6db-4a26-b750-c570f0c2bc87"}}},{"cell_type":"code","source":["file_path = f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\nairbnb_df = spark.read.format(\"delta\").load(file_path)\n\ntrain_df, test_df = airbnb_df.randomSplit([.8, .2], seed=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f273121-dc20-4a59-be08-77826567a6cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_delta_path = working_dir + \"/train.delta\"\ntest_delta_path = working_dir + \"/test.delta\"\n\n# In case paths already exists\ndbutils.fs.rm(train_delta_path, True)\ndbutils.fs.rm(test_delta_path, True)\n\ntrain_df.write.mode(\"overwrite\").format(\"delta\").save(train_delta_path)\ntest_df.write.mode(\"overwrite\").format(\"delta\").save(test_delta_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47b6aea4-8363-4c08-9d86-ebd117995524"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's now read in our train and test Delta tables, specifying that we want the first version of these tables. This <a href=\"https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html\" target=\"_blank\">blog post</a> has a great example of how to read in a Delta table at a given version."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a36cec74-c137-42e3-97e0-0512a12b7bc5"}}},{"cell_type":"code","source":["# TODO\ndata_version = 0\ntrain_delta = spark.read.format('delta').option('versionAsOf',data_version).load(train_delta_path)\ntest_delta = spark.read.format('delta').option('versionAsOf',data_version).load(test_delta_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5d50e93-e2e8-4198-9cd6-ab1361695e41"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Review Delta Table History\nAll the transactions for this table are stored within this table including the initial set of insertions, update, delete, merge, and inserts."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cc4f42f-3c34-449c-9038-303250f881e9"}}},{"cell_type":"code","source":["display(spark.sql(f\"DESCRIBE HISTORY delta.`{train_delta_path}`\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c780fb95-92f8-4c4b-bb8b-b856b817eae9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[0,"2022-08-26T06:25:39.000+0000","6997591375752473","manujkumar.joshi@celebaltech.com","WRITE",{"mode":"Overwrite","partitionBy":"[]"},null,["2051889157726538"],"0822-094520-n0irdqef",null,"WriteSerializable",false,{"numFiles":"4","numOutputRows":"5786","numOutputBytes":"208617"},null,"Databricks-Runtime/10.4.x-scala2.12"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"version","type":"\"long\"","metadata":"{}"},{"name":"timestamp","type":"\"timestamp\"","metadata":"{}"},{"name":"userId","type":"\"string\"","metadata":"{}"},{"name":"userName","type":"\"string\"","metadata":"{}"},{"name":"operation","type":"\"string\"","metadata":"{}"},{"name":"operationParameters","type":"{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}","metadata":"{}"},{"name":"job","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"notebook","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"clusterId","type":"\"string\"","metadata":"{}"},{"name":"readVersion","type":"\"long\"","metadata":"{}"},{"name":"isolationLevel","type":"\"string\"","metadata":"{}"},{"name":"isBlindAppend","type":"\"boolean\"","metadata":"{}"},{"name":"operationMetrics","type":"{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}","metadata":"{}"},{"name":"userMetadata","type":"\"string\"","metadata":"{}"},{"name":"engineInfo","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>0</td><td>2022-08-26T06:25:39.000+0000</td><td>6997591375752473</td><td>manujkumar.joshi@celebaltech.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(2051889157726538)</td><td>0822-094520-n0irdqef</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 4, numOutputRows -> 5786, numOutputBytes -> 208617)</td><td>null</td><td>Databricks-Runtime/10.4.x-scala2.12</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["By default Delta tables <a href=\"https://docs.databricks.com/delta/delta-batch.html#data-retention\" target=\"_blank\">keep a commit history of 30 days</a>. This retention period can be adjusted by setting **`delta.logRetentionDuration`**, which will determine how far back in time you can go. Note that setting this can result in storage costs to go up. \n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"/> Be aware that versioning with Delta in this manner may not be feasible as a long term solution. The retention period of Delta tables can be increased, but with that comes additional costs to storage. Alternative methods of data versioning when training models and tracking to MLflow is to save copies of the datasets, either as an MLflow artifact (for a small dataset), or save to a separate distributed location and record the location of the underlying dataset as a tag in MLflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da2ad545-1755-47c0-8eff-5fe8d226a0d3"}}},{"cell_type":"markdown","source":["### Step 2. Log initial run to MLflow\n\n- **Let's first log a run to MLflow where we use all features**. We use the same approach with RFormula as before. \n- **This time however, let's also log both the version of our data and the data path to MLflow.**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b605b9e2-beaa-4922-a2b3-1b2a681fc94e"}}},{"cell_type":"code","source":["# TODO\nimport mlflow\nimport mlflow.spark\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.feature import RFormula\n\nwith mlflow.start_run(run_name=\"lr_model\") as run:\n    # Log parameters\n    mlflow.log_param(\"data_path\", train_delta_path)  \n    mlflow.log_param('data_version',data_version)\n    mlflow.log_param('data_path',train_delta_path)\n    # TODO: Log label: price-all-features\n    # TODO: Log data_version: data_version\n\n\n    # Create pipeline\n    r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n    lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n    pipeline = Pipeline(stages = [r_formula, lr])\n    model = pipeline.fit(train_delta)\n\n    # Log pipeline\n    # TODO: Log model: model\n    mlflow.spark.log_model(model,'model')\n\n    # Create predictions and metrics\n    pred_df = model.transform(test_delta)\n    regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n\n    # Log metrics\n    mlflow.log_metric('rmse',rmse)\n    mlflow.log_metric('r2',r2)\n    # TODO: Log RMSE\n    # TODO: Log R2\n\n    run_id = run.info.run_id"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae783c66-e638-42fc-bf30-d19cee78d2a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Â Step 3. Register model and move to staging using MLflow Model Registry\n\nWe are happy with the performance of the above model and want to move it to staging. Let's create the model and register it to the MLflow model registry.\n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"/> Make sure the path to **`model_uri`** matches the subdirectory (the second argument to **`mlflow.log_model()`**) included above."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"187d13e0-18aa-460d-b713-8ebe71b77e07"}}},{"cell_type":"code","source":["model_name = f\"{cleaned_username}_mllib_lr\"\nmodel_uri = f\"runs:/{run_id}/model\"\n\nmodel_details = mlflow.register_model(model_uri=model_uri, name=model_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39b7ca64-133a-4de2-82d1-ad6c0e29670b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Successfully registered model &#39;manujkumar_joshi_mllib_lr&#39;.\n2022/08/26 06:46:22 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: manujkumar_joshi_mllib_lr, version 1\nCreated version &#39;1&#39; of model &#39;manujkumar_joshi_mllib_lr&#39;.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Successfully registered model &#39;manujkumar_joshi_mllib_lr&#39;.\n2022/08/26 06:46:22 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: manujkumar_joshi_mllib_lr, version 1\nCreated version &#39;1&#39; of model &#39;manujkumar_joshi_mllib_lr&#39;.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Transition model to staging."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4983deb3-4be3-4ea7-ba23-6bdf96e9ea22"}}},{"cell_type":"code","source":["from mlflow.tracking.client import MlflowClient\n\nclient = MlflowClient()\n\nclient.transition_model_version_stage(\n    name=model_name,\n    version=1,\n    stage=\"Staging\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ac3a0a2-8e0a-4a61-a272-f141bc283153"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[14]: &lt;ModelVersion: creation_timestamp=1661496382447, current_stage=&#39;Staging&#39;, description=&#39;&#39;, last_updated_timestamp=1661496444832, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;88d9ddcaed724dbc9c67fab13752c356&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/88d9ddcaed724dbc9c67fab13752c356/artifacts/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;1&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: &lt;ModelVersion: creation_timestamp=1661496382447, current_stage=&#39;Staging&#39;, description=&#39;&#39;, last_updated_timestamp=1661496444832, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;88d9ddcaed724dbc9c67fab13752c356&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/88d9ddcaed724dbc9c67fab13752c356/artifacts/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;1&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Define a utility method to wait until the model is ready\ndef wait_for_model(model_name, version, stage=\"None\", status=\"READY\", timeout=300):\n    import time\n\n    last_stage = \"unknown\"\n    last_status = \"unknown\"\n\n    for i in range(timeout):\n        model_version_details = client.get_model_version(name=model_name, version=version)\n        last_stage = str(model_version_details.current_stage)\n        last_status = str(model_version_details.status)\n        if last_status == str(status) and last_stage == str(stage):\n            return\n\n        time.sleep(1)\n\n    raise Exception(f\"The model {model_name} v{version} was not {status} after {timeout} seconds: {last_status}/{last_stage}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02e12a52-9614-4c2e-bd84-dc0e7ceab292"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Force our notebook to block until the model is ready\nwait_for_model(model_name, 1, stage=\"Staging\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99876956-0ed0-4c80-84a2-da4b0025a928"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Add a model description using <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient.update_registered_model\" target=\"_blank\">update_registered_model</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e497add-8a95-473b-88ed-309a50b4a552"}}},{"cell_type":"code","source":["# TODO\nclient.update_registered_model(\n  name = model_details.name,\n  description = 'forcasts prices of Airbnb based on inputs'\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e2991ec-328a-4474-87ea-0c656a0e1275"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[17]: &lt;RegisteredModel: creation_timestamp=1661496382105, description=&#39;forcasts prices of Airbnb based on inputs&#39;, last_updated_timestamp=1661496687413, latest_versions=[], name=&#39;manujkumar_joshi_mllib_lr&#39;, tags={}&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: &lt;RegisteredModel: creation_timestamp=1661496382105, description=&#39;forcasts prices of Airbnb based on inputs&#39;, last_updated_timestamp=1661496687413, latest_versions=[], name=&#39;manujkumar_joshi_mllib_lr&#39;, tags={}&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["wait_for_model(model_details.name, 1, stage=\"Staging\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"489f9352-6d53-4c07-a791-f65506f648a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###  Step 4. Feature Engineering: Evolve Data Schema\n\n- We now want to do some feature engineering with the aim of improving model performance; we can use Delta Lake to track older versions of the dataset. \n\n- We will add **`log_price`** as a new column and update our Delta table with it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa99099a-099d-4f8e-9bb0-a6e14f2c36ba"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col, log, exp\n\n# Create a new log_price column for both train and test datasets\ntrain_new = train_delta.withColumn(\"log_price\", log(col(\"price\")))\ntest_new = test_delta.withColumn(\"log_price\", log(col(\"price\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37a3be2e-bd00-486b-8b3c-5948feb18e93"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Save the updated DataFrames to **`train_delta_path`** and **`test_delta_path`**, respectively, passing the **`mergeSchema`** option to safely evolve its schema. \n\nTake a look at this <a href=\"https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html\" target=\"_blank\">blog</a> on Delta Lake for more information about **`mergeSchema`** (Schema Enforcement)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9447758d-4124-4f19-bc50-13354730be7b"}}},{"cell_type":"code","source":["# TODO\ntrain_new.write.option('mergeSchema','true').format('delta').mode('overwrite').save(train_delta_path)\ntest_new.write.option('mergeSchema','true').format('delta').mode('overwrite').save(test_delta_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aae98b1-0c20-48c6-b229-ead02bca14e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Look at the difference between the original & modified schemas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb21d01a-4050-4071-8e40-70e40d8962bc"}}},{"cell_type":"code","source":["set(train_new.schema.fields) ^ set(train_delta.schema.fields)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ebe8313-d3c6-4218-8f2a-2ba0fed9094f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[21]: {StructField(log_price,DoubleType,true)}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: {StructField(log_price,DoubleType,true)}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's review the Delta history of our **`train_delta`** table and load in the most recent versions of our train and test Delta tables."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"adc40e63-d159-45ce-b4bd-6160ca1307b1"}}},{"cell_type":"code","source":["display(spark.sql(f\"DESCRIBE HISTORY delta.`{train_delta_path}`\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e22935af-e3cf-4cf0-bbed-3c1fb3370631"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1,"2022-08-26T07:00:36.000+0000","6997591375752473","manujkumar.joshi@celebaltech.com","WRITE",{"mode":"Overwrite","partitionBy":"[]"},null,["2051889157726538"],"0822-094520-n0irdqef",0,"WriteSerializable",false,{"numFiles":"2","numOutputRows":"5786","numOutputBytes":"191364"},null,"Databricks-Runtime/10.4.x-scala2.12"],[0,"2022-08-26T06:25:39.000+0000","6997591375752473","manujkumar.joshi@celebaltech.com","WRITE",{"mode":"Overwrite","partitionBy":"[]"},null,["2051889157726538"],"0822-094520-n0irdqef",null,"WriteSerializable",false,{"numFiles":"4","numOutputRows":"5786","numOutputBytes":"208617"},null,"Databricks-Runtime/10.4.x-scala2.12"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"version","type":"\"long\"","metadata":"{}"},{"name":"timestamp","type":"\"timestamp\"","metadata":"{}"},{"name":"userId","type":"\"string\"","metadata":"{}"},{"name":"userName","type":"\"string\"","metadata":"{}"},{"name":"operation","type":"\"string\"","metadata":"{}"},{"name":"operationParameters","type":"{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}","metadata":"{}"},{"name":"job","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"notebook","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"clusterId","type":"\"string\"","metadata":"{}"},{"name":"readVersion","type":"\"long\"","metadata":"{}"},{"name":"isolationLevel","type":"\"string\"","metadata":"{}"},{"name":"isBlindAppend","type":"\"boolean\"","metadata":"{}"},{"name":"operationMetrics","type":"{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}","metadata":"{}"},{"name":"userMetadata","type":"\"string\"","metadata":"{}"},{"name":"engineInfo","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>1</td><td>2022-08-26T07:00:36.000+0000</td><td>6997591375752473</td><td>manujkumar.joshi@celebaltech.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(2051889157726538)</td><td>0822-094520-n0irdqef</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 2, numOutputRows -> 5786, numOutputBytes -> 191364)</td><td>null</td><td>Databricks-Runtime/10.4.x-scala2.12</td></tr><tr><td>0</td><td>2022-08-26T06:25:39.000+0000</td><td>6997591375752473</td><td>manujkumar.joshi@celebaltech.com</td><td>WRITE</td><td>Map(mode -> Overwrite, partitionBy -> [])</td><td>null</td><td>List(2051889157726538)</td><td>0822-094520-n0irdqef</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 4, numOutputRows -> 5786, numOutputBytes -> 208617)</td><td>null</td><td>Databricks-Runtime/10.4.x-scala2.12</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["data_version = 1\ntrain_delta_new = spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(train_delta_path)  \ntest_delta_new = spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(test_delta_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fd109a6-ccbb-4819-a402-92351094cbd1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Step 5. Use **`log_price`** as target and track run with MLflow\n\nRetrain the model on the updated data and compare its performance to the original, logging results to MLflow."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46a8c578-da9c-4471-ab3a-351d8ccf2c1f"}}},{"cell_type":"code","source":["with mlflow.start_run(run_name=\"lr_log_model\") as run:\n    # Log parameters\n    mlflow.log_param(\"label\", \"log-price\")\n    mlflow.log_param(\"data_version\", data_version)\n    mlflow.log_param(\"data_path\", train_delta_path)    \n\n    # Create pipeline\n    r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")  \n    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n    pipeline = Pipeline(stages = [r_formula, lr])\n    pipeline_model = pipeline.fit(train_delta_new)\n\n    # Log model and update the registered model\n    mlflow.spark.log_model(\n        spark_model=pipeline_model,\n        artifact_path=\"log-model\",\n        registered_model_name=model_name\n    )  \n\n    # Create predictions and metrics\n    pred_df = pipeline_model.transform(test_delta)\n    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n\n    # Log metrics\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.log_metric(\"r2\", r2)  \n\n    run_id = run.info.run_id"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b481c24-79d6-4699-8bce-096b30676bd0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Registered model &#39;manujkumar_joshi_mllib_lr&#39; already exists. Creating a new version of this model...\n2022/08/26 07:07:23 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: manujkumar_joshi_mllib_lr, version 2\nCreated version &#39;2&#39; of model &#39;manujkumar_joshi_mllib_lr&#39;.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registered model &#39;manujkumar_joshi_mllib_lr&#39; already exists. Creating a new version of this model...\n2022/08/26 07:07:23 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: manujkumar_joshi_mllib_lr, version 2\nCreated version &#39;2&#39; of model &#39;manujkumar_joshi_mllib_lr&#39;.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Step 6. Compare performance across runs by looking at Delta table versions \n\nUse MLflow's <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.search_runs\" target=\"_blank\">**`mlflow.search_runs`**</a> API to identify runs according to the version of data the run was trained on. Let's compare our runs according to our data versions.\n\nFilter based on **`params.data_path`** and **`params.data_version`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2fda284-13ac-41e7-8837-ed7277d720b0"}}},{"cell_type":"code","source":["# TODO\ndata_version = 0\n\nmlflow.search_runs(filter_string=f\"params.data_path='{train_delta_path}' and params.data_version='{data_version}'\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8dc8a1db-a6eb-4700-82b3-054259c5e1ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[26]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.rmse</th>\n      <th>metrics.r2</th>\n      <th>params.data_path</th>\n      <th>params.data_version</th>\n      <th>tags.mlflow.databricks.cluster.id</th>\n      <th>tags.mlflow.databricks.notebookRevisionID</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.databricks.workspaceID</th>\n      <th>tags.mlflow.databricks.workspaceURL</th>\n      <th>tags.mlflow.databricks.notebookPath</th>\n      <th>tags.mlflow.source.name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.mlflow.databricks.notebookID</th>\n      <th>tags.mlflow.source.type</th>\n      <th>tags.mlflow.log-model.history</th>\n      <th>tags.mlflow.databricks.cluster.info</th>\n      <th>tags.mlflow.databricks.notebook.commandID</th>\n      <th>tags.mlflow.databricks.webappURL</th>\n      <th>tags.mlflow.databricks.cluster.libraries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>88d9ddcaed724dbc9c67fab13752c356</td>\n      <td>2051889157726538</td>\n      <td>FINISHED</td>\n      <td>dbfs:/databricks/mlflow-tracking/2051889157726...</td>\n      <td>2022-08-26 06:42:07.962000+00:00</td>\n      <td>2022-08-26 06:44:27.834000+00:00</td>\n      <td>391.776823</td>\n      <td>0.129978</td>\n      <td>dbfs:/user/manujkumar.joshi@celebaltech.com/db...</td>\n      <td>0</td>\n      <td>0822-094520-n0irdqef</td>\n      <td>1661496267996</td>\n      <td>manujkumar.joshi@celebaltech.com</td>\n      <td>2542766428318180</td>\n      <td>adb-2542766428318180.0.azuredatabricks.net</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>lr_model</td>\n      <td>2051889157726538</td>\n      <td>NOTEBOOK</td>\n      <td>[{\"artifact_path\":\"model\",\"flavors\":{\"spark\":{...</td>\n      <td>{\"cluster_name\":\"AjeetSingh Charan's Cluster\",...</td>\n      <td>2243176141899946539_7483794869853950968_ba4857...</td>\n      <td>https://centralindia.azuredatabricks.net</td>\n      <td>{\"installable\":[],\"redacted\":[]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.rmse</th>\n      <th>metrics.r2</th>\n      <th>params.data_path</th>\n      <th>params.data_version</th>\n      <th>tags.mlflow.databricks.cluster.id</th>\n      <th>tags.mlflow.databricks.notebookRevisionID</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.databricks.workspaceID</th>\n      <th>tags.mlflow.databricks.workspaceURL</th>\n      <th>tags.mlflow.databricks.notebookPath</th>\n      <th>tags.mlflow.source.name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.mlflow.databricks.notebookID</th>\n      <th>tags.mlflow.source.type</th>\n      <th>tags.mlflow.log-model.history</th>\n      <th>tags.mlflow.databricks.cluster.info</th>\n      <th>tags.mlflow.databricks.notebook.commandID</th>\n      <th>tags.mlflow.databricks.webappURL</th>\n      <th>tags.mlflow.databricks.cluster.libraries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>88d9ddcaed724dbc9c67fab13752c356</td>\n      <td>2051889157726538</td>\n      <td>FINISHED</td>\n      <td>dbfs:/databricks/mlflow-tracking/2051889157726...</td>\n      <td>2022-08-26 06:42:07.962000+00:00</td>\n      <td>2022-08-26 06:44:27.834000+00:00</td>\n      <td>391.776823</td>\n      <td>0.129978</td>\n      <td>dbfs:/user/manujkumar.joshi@celebaltech.com/db...</td>\n      <td>0</td>\n      <td>0822-094520-n0irdqef</td>\n      <td>1661496267996</td>\n      <td>manujkumar.joshi@celebaltech.com</td>\n      <td>2542766428318180</td>\n      <td>adb-2542766428318180.0.azuredatabricks.net</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>lr_model</td>\n      <td>2051889157726538</td>\n      <td>NOTEBOOK</td>\n      <td>[{\"artifact_path\":\"model\",\"flavors\":{\"spark\":{...</td>\n      <td>{\"cluster_name\":\"AjeetSingh Charan's Cluster\",...</td>\n      <td>2243176141899946539_7483794869853950968_ba4857...</td>\n      <td>https://centralindia.azuredatabricks.net</td>\n      <td>{\"installable\":[],\"redacted\":[]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO\ndata_version = 1\n\nmlflow.search_runs(filter_string=f\"params.data_path='{train_delta_path}' and params.data_version='{data_version}'\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1346ebe9-b2a5-4716-a4c4-0e310a8e4ca9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.rmse</th>\n      <th>metrics.r2</th>\n      <th>params.data_path</th>\n      <th>params.label</th>\n      <th>params.data_version</th>\n      <th>tags.mlflow.databricks.cluster.id</th>\n      <th>tags.mlflow.databricks.notebookRevisionID</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.databricks.workspaceID</th>\n      <th>tags.mlflow.databricks.workspaceURL</th>\n      <th>tags.mlflow.databricks.notebookPath</th>\n      <th>tags.mlflow.source.name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.mlflow.databricks.notebookID</th>\n      <th>tags.mlflow.source.type</th>\n      <th>tags.mlflow.log-model.history</th>\n      <th>tags.mlflow.databricks.cluster.info</th>\n      <th>tags.mlflow.databricks.notebook.commandID</th>\n      <th>tags.mlflow.databricks.webappURL</th>\n      <th>tags.mlflow.databricks.cluster.libraries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8a22e59b906440039f3da253e3688adc</td>\n      <td>2051889157726538</td>\n      <td>FINISHED</td>\n      <td>dbfs:/databricks/mlflow-tracking/2051889157726...</td>\n      <td>2022-08-26 07:05:07.325000+00:00</td>\n      <td>2022-08-26 07:07:50.344000+00:00</td>\n      <td>380.595604</td>\n      <td>0.178929</td>\n      <td>dbfs:/user/manujkumar.joshi@celebaltech.com/db...</td>\n      <td>log-price</td>\n      <td>1</td>\n      <td>0822-094520-n0irdqef</td>\n      <td>1661497670535</td>\n      <td>manujkumar.joshi@celebaltech.com</td>\n      <td>2542766428318180</td>\n      <td>adb-2542766428318180.0.azuredatabricks.net</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>lr_log_model</td>\n      <td>2051889157726538</td>\n      <td>NOTEBOOK</td>\n      <td>[{\"artifact_path\":\"log-model\",\"flavors\":{\"spar...</td>\n      <td>{\"cluster_name\":\"AjeetSingh Charan's Cluster\",...</td>\n      <td>2243176141899946539_7576759484991374895_66753a...</td>\n      <td>https://centralindia.azuredatabricks.net</td>\n      <td>{\"installable\":[],\"redacted\":[]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>experiment_id</th>\n      <th>status</th>\n      <th>artifact_uri</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>metrics.rmse</th>\n      <th>metrics.r2</th>\n      <th>params.data_path</th>\n      <th>params.label</th>\n      <th>params.data_version</th>\n      <th>tags.mlflow.databricks.cluster.id</th>\n      <th>tags.mlflow.databricks.notebookRevisionID</th>\n      <th>tags.mlflow.user</th>\n      <th>tags.mlflow.databricks.workspaceID</th>\n      <th>tags.mlflow.databricks.workspaceURL</th>\n      <th>tags.mlflow.databricks.notebookPath</th>\n      <th>tags.mlflow.source.name</th>\n      <th>tags.mlflow.runName</th>\n      <th>tags.mlflow.databricks.notebookID</th>\n      <th>tags.mlflow.source.type</th>\n      <th>tags.mlflow.log-model.history</th>\n      <th>tags.mlflow.databricks.cluster.info</th>\n      <th>tags.mlflow.databricks.notebook.commandID</th>\n      <th>tags.mlflow.databricks.webappURL</th>\n      <th>tags.mlflow.databricks.cluster.libraries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8a22e59b906440039f3da253e3688adc</td>\n      <td>2051889157726538</td>\n      <td>FINISHED</td>\n      <td>dbfs:/databricks/mlflow-tracking/2051889157726...</td>\n      <td>2022-08-26 07:05:07.325000+00:00</td>\n      <td>2022-08-26 07:07:50.344000+00:00</td>\n      <td>380.595604</td>\n      <td>0.178929</td>\n      <td>dbfs:/user/manujkumar.joshi@celebaltech.com/db...</td>\n      <td>log-price</td>\n      <td>1</td>\n      <td>0822-094520-n0irdqef</td>\n      <td>1661497670535</td>\n      <td>manujkumar.joshi@celebaltech.com</td>\n      <td>2542766428318180</td>\n      <td>adb-2542766428318180.0.azuredatabricks.net</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>/Users/manujkumar.joshi@celebaltech.com/Scalab...</td>\n      <td>lr_log_model</td>\n      <td>2051889157726538</td>\n      <td>NOTEBOOK</td>\n      <td>[{\"artifact_path\":\"log-model\",\"flavors\":{\"spar...</td>\n      <td>{\"cluster_name\":\"AjeetSingh Charan's Cluster\",...</td>\n      <td>2243176141899946539_7576759484991374895_66753a...</td>\n      <td>https://centralindia.azuredatabricks.net</td>\n      <td>{\"installable\":[],\"redacted\":[]}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Which version of the data produced the best model?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0183a5f-5093-4cad-900b-30914df1fe9e"}}},{"cell_type":"markdown","source":["### Step 7. Move best performing model to production using MLflow model registry\n\nGet the most recent model version and move it to production."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71c788cc-c8be-442a-933b-e1f5edcbe165"}}},{"cell_type":"code","source":["model_version_infos = client.search_model_versions(f\"name = '{model_name}'\")\nnew_model_version = max([model_version_info.version for model_version_info in model_version_infos])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35cba9c9-cbfc-4628-b13a-79ab48988576"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["client.update_model_version(\n    name=model_name,\n    version=new_model_version,\n    description=\"This model version was built using a MLlib Linear Regression model with all features and log_price as predictor.\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1afb6a4c-f2b8-4e44-8969-1d3410254290"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;None&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661497979159, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;None&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661497979159, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["model_version_details = client.get_model_version(name=model_name, version=new_model_version)\nmodel_version_details.status"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed8d304e-095c-4bf8-9ea6-b62df9ea91a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[30]: &#39;READY&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[30]: &#39;READY&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["wait_for_model(model_name, new_model_version)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0171282a-a7fc-4655-9d58-535e74ca8fbf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO\n# Move Model into Production\nclient.transition_model_version_stage(\n  name = model_name,\n  version= new_model_version,\n  stage= 'Production'\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97919deb-5dad-4443-b4da-00d9d3603229"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[32]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;Production&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661498076045, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[32]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;Production&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661498076045, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["wait_for_model(model_name, new_model_version, \"Production\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b974bfc7-b9b9-4402-b186-9dd16613aa89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Have a look at the MLflow model registry UI to check that your models have been successfully registered. You should see that version 1 of your model is now in staging, with version 2 in production."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ebb1c3d-f37a-4562-b3f4-a4b83581c726"}}},{"cell_type":"markdown","source":["### To finish the lab, let's clean up by archiving both model versions and deleting the whole model from the registry"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9f4de79-915e-4f94-96aa-eea99959642b"}}},{"cell_type":"code","source":["client.transition_model_version_stage(\n    name=model_name,\n    version=1,\n    stage=\"Archived\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c94c22b3-c7ff-4fc5-97e5-88bdf96077ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[34]: &lt;ModelVersion: creation_timestamp=1661496382447, current_stage=&#39;Archived&#39;, description=&#39;&#39;, last_updated_timestamp=1661498148192, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;88d9ddcaed724dbc9c67fab13752c356&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/88d9ddcaed724dbc9c67fab13752c356/artifacts/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;1&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[34]: &lt;ModelVersion: creation_timestamp=1661496382447, current_stage=&#39;Archived&#39;, description=&#39;&#39;, last_updated_timestamp=1661498148192, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;88d9ddcaed724dbc9c67fab13752c356&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/88d9ddcaed724dbc9c67fab13752c356/artifacts/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;1&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["wait_for_model(model_name, 1, \"Archived\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d2df76e-5ce3-42d1-8183-7481f3e54223"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["client.transition_model_version_stage(\n    name=model_name,\n    version=2,\n    stage=\"Archived\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33c14ec0-1f24-4091-a69c-5d986bce93cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[36]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;Archived&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661498156456, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: &lt;ModelVersion: creation_timestamp=1661497643852, current_stage=&#39;Archived&#39;, description=(&#39;This model version was built using a MLlib Linear Regression model with all &#39;\n &#39;features and log_price as predictor.&#39;), last_updated_timestamp=1661498156456, name=&#39;manujkumar_joshi_mllib_lr&#39;, run_id=&#39;8a22e59b906440039f3da253e3688adc&#39;, run_link=&#39;&#39;, source=&#39;dbfs:/databricks/mlflow-tracking/2051889157726538/8a22e59b906440039f3da253e3688adc/artifacts/log-model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;6997591375752473&#39;, version=&#39;2&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["wait_for_model(model_name, 2, \"Archived\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa72b145-24b2-40e4-9dfa-6746621f6a60"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["client.delete_registered_model(model_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32b1243f-537c-4d5d-8ed2-b53747d15849"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"daff2999-6b4d-4155-aaf7-393efd010492"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 05L - MLflow Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157726538}},"nbformat":4,"nbformat_minor":0}
