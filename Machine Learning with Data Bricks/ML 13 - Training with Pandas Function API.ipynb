{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"996ffde8-2875-4590-a37f-84387361f7d6"}}},{"cell_type":"markdown","source":["# Training with Pandas Function API\n\nThis notebook demonstrates how to use Pandas Function API to manage and scale machine learning models for IoT devices. \n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Use <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.GroupedData.applyInPandas.html?highlight=applyinpandas#pyspark.sql.GroupedData.applyInPandas\" target=\"_blank\"> **`.groupBy().applyInPandas()`** </a> to build many models in parallel for each IoT Device"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21b5366c-1e56-4d13-9508-27756b3d0c04"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70fad874-4f61-48df-bd2d-c63b2c26effd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Create dummy data with:\n- **`device_id`**: 10 different devices\n- **`record_id`**: 10k unique records\n- **`feature_1`**: a feature for model training\n- **`feature_2`**: a feature for model training\n- **`feature_3`**: a feature for model training\n- **`label`**: the variable we're trying to predict"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f76a7d6f-31d7-41e8-8c69-36106b3cee31"}}},{"cell_type":"code","source":["import pyspark.sql.functions as f\n\ndf = (spark\n      .range(1000*100)\n      .select(f.col(\"id\").alias(\"record_id\"), (f.col(\"id\")%10).alias(\"device_id\"))\n      .withColumn(\"feature_1\", f.rand() * 1)\n      .withColumn(\"feature_2\", f.rand() * 2)\n      .withColumn(\"feature_3\", f.rand() * 3)\n      .withColumn(\"label\", (f.col(\"feature_1\") + f.col(\"feature_2\") + f.col(\"feature_3\")) + f.rand())\n     )\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea1b7fb3-1a03-4212-8422-f318f2411fc5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define the return schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3edf8766-31de-4f62-a471-b27caec207d2"}}},{"cell_type":"code","source":["import pyspark.sql.types as t\n\ntrain_return_schema = t.StructType([\n    t.StructField(\"device_id\", t.IntegerType()), # unique device ID\n    t.StructField(\"n_used\", t.IntegerType()),    # number of records used in training\n    t.StructField(\"model_path\", t.StringType()), # path to the model for a given device\n    t.StructField(\"mse\", t.FloatType())          # metric for model performance\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74d60a54-38b8-487d-bbc4-ef0a36ff28d4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define a pandas function that takes all the data for a given device, train a model, saves it as a nested run, and returns a spark object with the above schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffe346c8-4425-4029-a229-157370880e1b"}}},{"cell_type":"code","source":["import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef train_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Trains an sklearn model on grouped instances\n    \"\"\"\n    # Pull metadata\n    device_id = df_pandas[\"device_id\"].iloc[0]\n    n_used = df_pandas.shape[0]\n    run_id = df_pandas[\"run_id\"].iloc[0] # Pulls run ID to do a nested run\n\n    # Train the model\n    X = df_pandas[[\"feature_1\", \"feature_2\", \"feature_3\"]]\n    y = df_pandas[\"label\"]\n    rf = RandomForestRegressor()\n    rf.fit(X, y)\n\n    # Evaluate the model\n    predictions = rf.predict(X)\n    mse = mean_squared_error(y, predictions) # Note we could add a train/test split\n\n    # Resume the top-level training\n    with mlflow.start_run(run_id=run_id) as outer_run:\n        # Small hack for for running as a job\n        experiment_id = outer_run.info.experiment_id\n        print(f\"Current experiment_id = {experiment_id}\")\n\n        # Create a nested run for the specific device\n        with mlflow.start_run(run_name=str(device_id), nested=True, experiment_id=experiment_id) as run:\n            mlflow.sklearn.log_model(rf, str(device_id))\n            mlflow.log_metric(\"mse\", mse)\n\n            artifact_uri = f\"runs:/{run.info.run_id}/{device_id}\"\n            # Create a return pandas DataFrame that matches the schema above\n            return_df = pd.DataFrame([[device_id, n_used, artifact_uri, mse]], \n                                    columns=[\"device_id\", \"n_used\", \"model_path\", \"mse\"])\n\n    return return_df \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4ed8965-f3bb-4b64-bd35-d13d412f19de"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Apply the pandas function to grouped data. \n\nNote that the way you would apply this in practice depends largely on where the data for inference is located. In this example, we'll reuse the training data which contains our device and run id's."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0513916-4c6c-456d-b3da-25c87a0041ed"}}},{"cell_type":"code","source":["with mlflow.start_run(run_name=\"Training session for all devices\") as run:\n    run_id = run.info.run_id\n\n    model_directories_df = (df\n        .withColumn(\"run_id\", f.lit(run_id)) # Add run_id\n        .groupby(\"device_id\")\n        .applyInPandas(train_model, schema=train_return_schema)\n        .cache()\n    )\n\ncombined_df = df.join(model_directories_df, on=\"device_id\", how=\"left\")\ndisplay(combined_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de027f69-3550-47bb-a3dd-bc1594c3b729"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define a pandas function to apply the model.  *This needs only one read from DBFS per device.*"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe8b88d7-1e76-404b-86e9-c5caa841237a"}}},{"cell_type":"code","source":["apply_return_schema = t.StructType([\n    t.StructField(\"record_id\", t.IntegerType()),\n    t.StructField(\"prediction\", t.FloatType())\n])\n\ndef apply_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Applies model to data for a particular device, represented as a pandas DataFrame\n    \"\"\"\n    model_path = df_pandas[\"model_path\"].iloc[0]\n\n    input_columns = [\"feature_1\", \"feature_2\", \"feature_3\"]\n    X = df_pandas[input_columns]\n\n    model = mlflow.sklearn.load_model(model_path)\n    prediction = model.predict(X)\n\n    return_df = pd.DataFrame({\n        \"record_id\": df_pandas[\"record_id\"],\n        \"prediction\": prediction\n    })\n    return return_df\n\nprediction_df = combined_df.groupby(\"device_id\").applyInPandas(apply_model, schema=apply_return_schema)\ndisplay(prediction_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b739412b-435e-440f-a530-82afc56dccbe"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6801503-87d1-4f93-8a5d-faa2cee36ef0"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 13 - Training with Pandas Function API","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157726829}},"nbformat":4,"nbformat_minor":0}
