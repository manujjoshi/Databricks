{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"006b7b69-c499-4c22-94b9-f74dc82e6313"}}},{"cell_type":"markdown","source":["# XGBoost\n\nUp until this point, we have only used SparkML. Let's look a third party library for Gradient Boosted Trees. \n \nEnsure that you are using the <a href=\"https://docs.microsoft.com/en-us/azure/databricks/runtime/mlruntime\" target=\"_blank\">Databricks Runtime for ML</a> because that has Distributed XGBoost already installed. \n\n**Question**: How do gradient boosted trees differ from random forests? Which parts can be parallelized?\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Use 3rd party libraries (XGBoost) to further improve your model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45e9ed3a-58b3-4357-b57e-bf1e17ace89c"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3c0fbaf-c19c-48cd-bb5d-3511893129a6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Data Preparation\n\nLet's go ahead and index all of our categorical features, and set our label to be **`log(price)`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0adb9688-9d40-44f6-b612-9805044098d1"}}},{"cell_type":"code","source":["from pyspark.sql.functions import log, col\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\n\nfile_path = f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\nairbnb_df = spark.read.format(\"delta\").load(file_path)\ntrain_df, test_df = airbnb_df.withColumn(\"label\", log(col(\"price\"))).randomSplit([.8, .2], seed=42)\n\ncategorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\nindex_output_cols = [x + \"Index\" for x in categorical_cols]\n\nstring_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n\nnumeric_cols = [field for (field, dataType) in train_df.dtypes if ((dataType == \"double\") & (field != \"price\") & (field != \"label\"))]\nassembler_inputs = index_output_cols + numeric_cols\nvec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8014c1fc-6d75-41b1-b6db-d832056030d7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Pyspark Distributed XGBoost\n\nLet's create our distributed XGBoost model. While technically not part of MLlib, you can integrate <a href=\"https://databricks.github.io/spark-deep-learning/_modules/sparkdl/xgboost/xgboost.html\" target=\"_blank\">XGBoost</a> into your ML Pipelines. \n\nTo use the distributed version of Pyspark XGBoost you can specify two additional parameters:\n\n* **`num_workers`**: The number of workers to distribute over. Requires MLR 9.0+.\n* **`use_gpu`**: Enable to utilize GPU based training for faster performance (optional).\n\n**NOTE:** **`use_gpu`** requires an ML GPU runtime. Currently, at most one GPU per worker will be used when doing distributed training."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ad2c7db-297b-4828-9a1c-2a29de22500e"}}},{"cell_type":"code","source":["from sparkdl.xgboost import XgboostRegressor\nfrom pyspark.ml import Pipeline\n\nparams = {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"random_state\": 42, \"missing\": 0}\n\nxgboost = XgboostRegressor(**params)\n\npipeline = Pipeline(stages=[string_indexer, vec_assembler, xgboost])\npipeline_model = pipeline.fit(train_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3939c6c4-3e02-41cc-acc7-256f88c8bdc8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate\n\nNow we can evaluate how well our XGBoost model performed. Don't forget to exponentiate!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09c9d174-2b99-42e4-b8f7-3a315b994ad9"}}},{"cell_type":"code","source":["from pyspark.sql.functions import exp, col\n\nlog_pred_df = pipeline_model.transform(test_df)\n\nexp_xgboost_df = log_pred_df.withColumn(\"prediction\", exp(col(\"prediction\")))\n\ndisplay(exp_xgboost_df.select(\"price\", \"prediction\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd38cfd7-2cdc-475d-aad7-636bc9954430"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Compute some metrics."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4caffb55-2af8-4c0a-be68-2c167427fcf6"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\nregression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n\nrmse = regression_evaluator.evaluate(exp_xgboost_df)\nr2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_xgboost_df)\nprint(f\"RMSE is {rmse}\")\nprint(f\"R2 is {r2}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f4311ba-d534-46ae-a869-0e175fd814e8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Alternative Gradient Boosted Approaches\n\nThere are lots of other gradient boosted approaches, such as <a href=\"https://catboost.ai/\" target=\"_blank\">CatBoost</a>, <a href=\"https://github.com/microsoft/LightGBM\" target=\"_blank\">LightGBM</a>, vanilla gradient boosted trees in <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html?highlight=gbt#pyspark.ml.classification.GBTClassifier\" target=\"_blank\">SparkML</a>/<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\" target=\"_blank\">scikit-learn</a>, etc. Each of these has their respective <a href=\"https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\" target=\"_blank\">pros and cons</a> that you can read more about."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"635f3986-5c4a-40b1-bfdb-7ac7f84cd9c8"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e83f5ae-293b-4510-a738-8cbdb2701042"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 11 - XGBoost","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157726702}},"nbformat":4,"nbformat_minor":0}
