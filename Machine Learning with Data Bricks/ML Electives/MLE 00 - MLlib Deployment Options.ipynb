{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c25d9cb-538a-4c78-bf9b-91e7c831f19b"}}},{"cell_type":"markdown","source":["![](https://files.training.databricks.com/images/301/deployment_options_mllib.png)\n\nThere are four main deployment options:\n* Batch pre-compute\n* Structured streaming\n* Low-latency model serving\n* Mobile/embedded (outside scope of class)\n\nWe have already seen how to do batch predictions using Spark. Now let's look at how to make predictions on streaming data.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Apply a SparkML model on a simulated stream of data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a4e5bc8-1637-4d15-8123-e4025be54388"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ee3e392-5afc-4ca5-a348-edaded9b9a87"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Load in Model & Data\n\nWe are loading in a repartitioned version of our dataset (100 partitions instead of 4) to see more incremental progress of the streaming predictions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"624adff8-b3cd-454c-9f52-e3affc6203df"}}},{"cell_type":"code","source":["from pyspark.ml.pipeline import PipelineModel\n\npipeline_path = f\"{datasets_dir}/airbnb/sf-listings/models/sf-listings-2019-03-06/pipeline_model\"\npipeline_model = PipelineModel.load(pipeline_path)\n\nrepartitioned_path =  f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean-100p.parquet/\"\nschema = spark.read.parquet(repartitioned_path).schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7c3083e-ea2a-429a-b2a8-67b99e0d3d1f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Simulate streaming data\n\n**NOTE**: You must specify a schema when creating a streaming source DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"532d3c1e-d471-494c-bf3c-0df1d78dfce5"}}},{"cell_type":"code","source":["streaming_data = (spark\n                 .readStream\n                 .schema(schema) # Can set the schema this way\n                 .option(\"maxFilesPerTrigger\", 1)\n                 .parquet(repartitioned_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cbfa652-0003-4247-935a-56cbaa49afce"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Make Predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91e5472c-efbb-40a0-b27d-c8d210cc66f8"}}},{"cell_type":"code","source":["stream_pred = pipeline_model.transform(streaming_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06d87c4b-ea80-4732-a269-7f29ec0078e2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's save our results."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"499b9a45-264b-4812-a181-54b44da112ea"}}},{"cell_type":"code","source":["import re\n\ncheckpoint_dir = working_dir + \"/stream_checkpoint\"\n# Clear out the checkpointing directory\ndbutils.fs.rm(checkpoint_dir, True) \n\n(stream_pred\n .writeStream\n .format(\"memory\")\n .option(\"checkpointLocation\", checkpoint_dir)\n .outputMode(\"append\")\n .queryName(\"pred_stream\")\n .start())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fed161f-cbe7-4b9b-a736-3e6f4d6497f8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["untilStreamIsReady(\"pred_stream\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"758d0d28-d6ca-4cc1-9ff0-53a85611c238"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["While this is running, take a look at the new Structured Streaming tab in the Spark UI."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"255dcbeb-fbd3-4724-9d27-418175e8f315"}}},{"cell_type":"code","source":["display(\n  sql(\"select * from pred_stream\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ecc0fb8-4807-4d5e-9309-c55a4508d514"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(\n  sql(\"select count(*) from pred_stream\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ae328bc-1596-4f9c-ae46-9fd48fae1a4d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now that we are done, make sure to stop the stream"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f1502d9-435b-49ea-92ef-6e2da661838a"}}},{"cell_type":"code","source":["for stream in spark.streams.active:\n    print(f\"Stopping {stream.name}\")\n    stream.stop()                  # Stop the active stream\n    try: stream.awaitTermination() # Wait for it to actually stop\n    except: pass                   # Don't care if stopping fails"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f099d1cd-aadf-465b-ab1d-d08a23da8341"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### What about Model Export?\n\n* <a href=\"https://onnx.ai/\" target=\"_blank\">ONNX</a>\n  * ONNX is very popular in the deep learning community allowing developers to switch between libraries and languages, but only has experimental support for MLlib.\n* DIY (Reimplement it yourself)\n  * Error-prone, fragile\n* 3rd party libraries\n  * See XGBoost notebook\n  * <a href=\"https://www.h2o.ai/products/h2o-sparkling-water/\" target=\"_blank\">H2O</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cccc672-78f8-4a3c-9b54-ed6cf9607afa"}}},{"cell_type":"markdown","source":["### Low-Latency Serving Solutions\n\nLow-latency serving can operate as quickly as tens to hundreds of milliseconds.  Custom solutions are normally backed by Docker and/or Flask (though Flask generally isn't recommended in production unless significant precations are taken).  Managed solutions also include:<br><br>\n\n* <a href=\"https://docs.databricks.com/applications/mlflow/model-serving.html\" target=\"_blank\">MLflow Model Serving</a>\n* <a href=\"https://azure.microsoft.com/en-us/services/machine-learning/\" target=\"_blank\">Azure Machine Learning</a>\n* <a href=\"https://aws.amazon.com/sagemaker/\" target=\"_blank\">SageMaker</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5505e2a7-90ca-4df0-883a-0fbcce0dcba6"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67dbbf72-7725-4eb5-bf30-10682908d806"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MLE 00 - MLlib Deployment Options","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157727982}},"nbformat":4,"nbformat_minor":0}
