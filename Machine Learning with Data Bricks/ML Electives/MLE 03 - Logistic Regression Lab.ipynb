{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47690033-a4c5-4d6e-aa97-89527f5851c7"}}},{"cell_type":"markdown","source":["# Classification: Logistic Regression\n\nUp until this point, we have only examined regression use cases. Now let's take a look at how to handle classification.\n\nFor this lab, we will use the same Airbnb dataset, but instead of predicting price, we will predict if host is a <a href=\"https://www.airbnb.com/superhost\" target=\"_blank\">superhost</a> or not in San Francisco.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Build a Logistic Regression model\n - Use various metrics to evaluate model performance"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af5f42e5-faa0-4a9a-8007-3ced4d6d4a8b"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c3e4eac-bcf0-4d71-bff8-c456bcbb4870"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["file_path = f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\nairbnb_df = spark.read.format(\"delta\").load(file_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8c6e95f-c05c-4b75-ad12-3336cd44c5af"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Baseline Model\n\nBefore we build any Machine Learning models, we want to build a baseline model to compare to. We are going to start by predicting if a host is a <a href=\"https://www.airbnb.com/superhost\" target=\"_blank\">superhost</a>. \n\nFor our baseline model, we are going to predict no on is a superhost and evaluate our accuracy. We will examine other metrics later as we build more complex models.\n\n0. Convert our **`host_is_superhost`** column (t/f) into 1/0 and call the resulting column **`label`**. DROP the **`host_is_superhost`** afterwards.\n0. Add a column to the resulting DataFrame called **`prediction`** which contains the literal value **`0.0`**. We will make a constant prediction that no one is a superhost.\n\nAfter we finish these two steps, then we can evaluate the \"model\" accuracy. \n\nSome helpful functions:\n* <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.when.html#pyspark.sql.functions.when\" target=\"_blank\">when()</a>\n* <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html?highlight=withcolumn#pyspark.sql.DataFrame.withColumn\" target=\"_blank\">withColumn()</a>\n* <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.lit.html?highlight=lit#pyspark.sql.functions.lit\" target=\"_blank\">lit()</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"559e20d3-cd27-4bda-bd2b-9bd9dbb35db5"}}},{"cell_type":"code","source":["# TODO\nfrom <FILL_IN>\n\nlabel_df = airbnb_df.<FILL_IN>\n\npred_df = label_df.<FILL_IN> # Add a prediction column"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89611945-cdef-459d-8740-f3f1fe2308d5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate model\n\nFor right now, let's use accuracy as our metric. This is available from <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html?highlight=multiclassclassificationevaluator#pyspark.ml.evaluation.MulticlassClassificationEvaluator\" target=\"_blank\">MulticlassClassificationEvaluator</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7538d90c-37b5-45d4-9f46-340ad9f88486"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nmc_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\nprint(f\"The accuracy is {100*mc_evaluator.evaluate(pred_df):.2f}%\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da3fe510-8e7e-4b56-9e68-bef67cf314c5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Train-Test Split\n\nAlright! Now we have built a baseline model. The next step is to split our data into a train-test split."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63e360fa-788e-4977-b11f-4499616df2ad"}}},{"cell_type":"code","source":["train_df, test_df = label_df.randomSplit([.8, .2], seed=42)\nprint(train_df.cache().count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba452dfc-9749-45d3-af62-b4659c6a1bc4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Visualize\n\nLet's look at the relationship between **`review_scores_rating`** and **`label`** in our training dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1c2ffb4-b5bd-4ff8-aa75-ea226305211a"}}},{"cell_type":"code","source":["display(train_df.select(\"review_scores_rating\", \"label\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1ecc2da-cf80-4a42-9f5e-c83eb6dca2ae"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Logistic Regression\n\nNow build a <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegression\" target=\"_blank\">logistic regression model</a> using all of the features (HINT: use RFormula). Put the pre-processing step and the Logistic Regression Model into a Pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cf6d8f6-8648-41f4-bb9c-7b0a0041cc24"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import RFormula\nfrom pyspark.ml.classification import LogisticRegression\n\nr_formula = RFormula(<FILL_IN>)\nlr = <FILL_IN>\npipeline = Pipeline(<FILL_IN>)\npipeline_model = pipeline.fit(<FILL_IN>)\npred_df = pipeline_model.transform(<FILL_IN>)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e0bcbcb-6081-4c0e-a65f-ab49fbc8d6ed"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate\n\nWhat is AUROC useful for? Try adding additional evaluation metrics, like Area Under PR Curve."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0383261-407b-4059-b918-ce8bdec24ad8"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n\nmc_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\nprint(f\"The accuracy is {100*mc_evaluator.evaluate(pred_df):.2f}%\")\n\nbc_evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\nprint(f\"The area under the ROC curve: {bc_evaluator.evaluate(pred_df):.2f}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33ff8eea-fba9-4ea1-be93-d23603e58ce3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Add Hyperparameter Tuning\n\nTry changing the hyperparameters of the logistic regression model using the cross-validator. By how much can you improve your metrics?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32dac784-a94a-4b39-af06-570ff01675a5"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidator\n\nparam_grid = <FILL_IN>\n\nevaluator = <FILL_IN>\n\ncv = <FILL_IN>\n\npipeline = <FILL_IN>\n\npipeline_model = <FILL_IN>\n\npred_df = <FILL_IN>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff2493fa-0767-4ce4-8ef0-b9ff54693f5e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate again"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d976675-ea29-40d3-892c-58ec61e3da63"}}},{"cell_type":"code","source":["mc_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\nprint(f\"The accuracy is {100*mc_evaluator.evaluate(pred_df):.2f}%\")\n\nbc_evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\nprint(f\"The area under the ROC curve: {bc_evaluator.evaluate(pred_df):.2f}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41b25f81-ccc5-4177-a049-df7f15ba0a1f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Super Bonus\n\nTry using MLflow to track your experiments!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1670574a-5279-4012-ba1c-a3fb52cdc7f4"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e8da68a-fd5f-4f11-9572-341325eda831"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MLE 03 - Logistic Regression Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157727855}},"nbformat":4,"nbformat_minor":0}
