{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ceab0b06-6fef-42a4-b5d8-df63bf2fb14e"}}},{"cell_type":"markdown","source":["# Databricks Best Practices\n\nIn this notebook, we will explore a wide array of best practices for working with Databricks.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Explore a general framework for debugging slow running jobs\n - Identify the security implications of various data access paradigms\n - Determine various cluster configuration issues including machine types, libraries, and jobs\n - Integrate Databricks notebooks and jobs with version control and the CLI"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4990d5b4-05aa-4eae-b8f7-517b6c8682e5"}}},{"cell_type":"markdown","source":["## Slow Running Jobs\n\nThe most common issues with slow running jobs are:<br><br>\n\n- **`Spill`**: Data is exhausting the cluster's memory and is spilling onto disk. Resolution: a cluster with more memory resources\n- **`Shuffle`**: Large amounts of data are being transferred across the cluster.  Resolution: optimize joins or refactor code to avoid shuffles\n- **`Skew/Stragglers`**: Partitioned data (in files or in memory) is skewed causing the \"curse of the last reducer\" where some partitions take longer to run.  Resolution: repartition to a multiple of the available cores or use skew hints\n- **`Small/Large Files`**: Too many small files are exhausting cluster resources since each file read needs its own thread or few large files are causing unused threads.  Resolution: rewrite data in a more optimized way or perform Delta file compaction\n\nYour debugging toolkit:<br><br>\n\n- Ganglia for CPU, network, and memory resources at a cluster or node level\n- Spark UI for most everything else (especially the storage and executor tabs)\n- Driver or worker logs for errors (especially with background processes)\n- Notebook tab of the clusters section to see if the intern is hogging your cluster again"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9983ee21-7d61-4572-91b1-156313ee4793"}}},{"cell_type":"markdown","source":["## Data Access and Security\n\nA few notes on data access:<br><br>\n\n* <a href=\"https://docs.databricks.com/data/databricks-file-system.html#mount-storage\" target=\"_blank\">Mount data for easy access</a>\n* <a href=\"https://docs.databricks.com/dev-tools/cli/secrets-cli.html#secrets-cli\" target=\"_blank\">Use secrets to secure credentials</a> (this keeps credentials out of the code)\n* Credential passthrough works in <a href=\"https://docs.databricks.com/dev-tools/cli/secrets-cli.html#secrets-cli\" target=\"_blank\">AWS</a> and <a href=\"https://docs.microsoft.com/en-us/azure/databricks/security/credential-passthrough/adls-passthrough\" target=\"_blank\">Azure</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37209af3-bbb2-45c1-9423-b8c09ba7253a"}}},{"cell_type":"markdown","source":["## Cluster Configuration, Libraries, and Jobs\n\nCluster types are:<br><br>\n\n- Memory optimized (with or without <a href=\"https://docs.databricks.com/delta/optimizations/delta-cache.html\" target=\"_blank\">Delta Cache Acceleration</a>\n- Compute optimized\n- Storage optimized\n- GPU accelerated\n- General Purpose\n\nGeneral rules of thumb:<br><br>\n\n- Smaller clusters of larger machine types for machine learning\n- One cluster per production workload\n- Don't share clusters for ML training (even in development)\n- <a href=\"https://docs.databricks.com/clusters/configure.html\" target=\"_blank\">See the docs for more specifics</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e89157e3-4894-4b66-8b9a-88fc992f1cb0"}}},{"cell_type":"markdown","source":["Library installation best practices:<br><br>\n  \n- <a href=\"https://docs.databricks.com/libraries/notebooks-python-libraries.html\" target=\"_blank\">Notebook-scoped Python libraries</a> ensure users on same cluster can have different libraries.  Also good for saving notebooks with their library dependencies\n- <a href=\"https://docs.databricks.com/clusters/init-scripts.html\" target=\"_blank\">Init scripts</a> ensure that code is ran before the JVM starts (good for certain libraries or environment configuration)\n- Some configuration variables need to be set on cluster start"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be447b1f-41f8-4166-bb0a-eba62b1b623c"}}},{"cell_type":"markdown","source":["Jobs best practices:<br><br>\n\n- Use <a href=\"https://docs.databricks.com/notebooks/notebook-workflows.html\" target=\"_blank\">notebook workflows</a>\n- <a href=\"https://docs.databricks.com/notebooks/widgets.html\" target=\"_blank\">Widgets</a> work for parameter passing\n- You can also run jars and wheels\n- Use the CLI for orchestration tools (e.g. Airflow)\n- <a href=\"https://docs.databricks.com/jobs.html\" target=\"_blank\">See the docs for more specifics</a>\n- Always specify a timeout interval to prevent infinitely running jobs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b596254-bfa3-4fbf-9e9e-4b8cb6cc2eed"}}},{"cell_type":"markdown","source":["## CLI and Version Control\n\nThe <a href=\"https://github.com/databricks/databricks-cli\" target=\"_blank\">Databricks CLI</a>:<br><br>\n\n * Programmatically export out all your notebooks to check into github\n * Can also import/export data, execute jobs, create clusters, and perform most other Workspace tasks\n\nGit integration can be accomplished in a few ways:<br><br>\n\n * Use the CLI to import/export notebooks and check into git manually\n * <a href=\"https://docs.databricks.com/notebooks/github-version-control.html\" target=\"_blank\">Use the built-in git integration</a>\n * <a href=\"https://www.youtube.com/watch?v=HsfMmBfQtvI\" target=\"_blank\">Use the next generation workspace for alternative project integration</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a0ef82e-ce61-4e65-9910-aebcebc9481c"}}},{"cell_type":"markdown","source":["Time permitting: exploring the <a href=\"https://docs.databricks.com/administration-guide/index.html\" target=\"_blank\">admin console!</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7b85fb5-3618-474a-93c2-7a28f2b172ae"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca4b142c-c05b-4c76-9996-2f270f953cb2"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MLE 05 - Databricks Best Practices","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157728003}},"nbformat":4,"nbformat_minor":0}
