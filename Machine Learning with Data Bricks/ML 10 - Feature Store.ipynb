{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fa17d65-8950-4dd7-b387-e8951f306383"}}},{"cell_type":"markdown","source":["# Feature Store\n\nThe <a href=\"https://docs.databricks.com/applications/machine-learning/feature-store.html\" target=\"_blank\">Databricks Feature Store</a> is a centralized repository of features. It enables feature sharing and discovery across your organization and also ensures that the same feature computation code is used for model training and inference.\n\nCheck out Feature Store Python API documentation <a href=\"https://docs.databricks.com/dev-tools/api/python/latest/index.html#feature-store-python-api-reference\" target=\"_blank\">here</a>.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you will:<br>\n - Build a feature store with the Databricks Feature Store\n - Update feature tables\n - Perform batch scoring"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e21eea4d-c2c5-4569-b07f-f2cef8b29215"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c5e2d2f-25d8-476a-98e5-04d808c1048f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import monotonically_increasing_id, lit, expr, rand\nimport uuid\nfrom databricks import feature_store\nfrom pyspark.sql.types import StringType, DoubleType\nfrom databricks.feature_store import feature_table, FeatureLookup\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5c364c8-dd27-4bd5-a80a-17a49fb2ffbd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's load in our data and generate a unique ID for each listing. The **`index`** column will serve as the \"key\" of the feature table and used to lookup features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"becc8085-1fca-4d67-bc4a-ba6d26d4ecb8"}}},{"cell_type":"code","source":["file_path = f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\nairbnb_df = spark.read.format(\"delta\").load(file_path).coalesce(1).withColumn(\"index\", monotonically_increasing_id())\ndisplay(airbnb_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c9fc026-540e-458d-8c7b-1da32878df4e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Create a new database and unique table name (in case you re-run the notebook multiple times)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fec03316-65d1-4c05-b77e-25672c9874d5"}}},{"cell_type":"code","source":["spark.sql(f\"CREATE DATABASE IF NOT EXISTS {cleaned_username}\")\ntable_name = f\"{cleaned_username}.airbnb_\" + str(uuid.uuid4())[:6]\nprint(table_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a49ff295-4fdb-4865-aa32-5b61efc5b286"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's start creating a <a href=\"https://docs.databricks.com/applications/machine-learning/feature-store.html#create-a-feature-table-in-databricks-feature-store\" target=\"_blank\">Feature Store Client</a> so we can populate our feature store."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e38bc93-eb06-455e-b3fc-82a5604c417d"}}},{"cell_type":"code","source":["fs = feature_store.FeatureStoreClient()\n\n# help(fs.create_table)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3231309f-a308-4ce8-996c-22bdc9febc20"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Create Feature Table\n\nNext, we can create the Feature Table using the **`create_table`** method.\n\nThis method takes a few parameters as inputs:\n* **`name`**- A feature table name of the form **`<database_name>.<table_name>`**\n* **`primary_keys`**- The primary key(s). If multiple columns are required, specify a list of column names.\n* **`df`**- Data to insert into this feature table.  The schema of **`features_df`** will be used as the feature table schema.\n* **`schema`**- Feature table schema. Note that either **`schema`** or **`features_df`** must be provided.\n* **`description`**- Description of the feature table\n* **`partition_columns`**- Column(s) used to partition the feature table."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7243162-6689-40b7-92ba-e4e4a0d7df6d"}}},{"cell_type":"markdown","source":["First we define a **`@feature_table`** that simply selects some numeric information from the data. This will become one feature store table when written later. A **`@feature_table`** is really just a function that computes a DataFrame defining the features in the table, from a source 'raw' DataFrame. It can be called directly for testing; by itself, it does not persist or publish features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb2be0cc-2682-421a-ad03-fb0bebd1ba86"}}},{"cell_type":"code","source":["## select numeric features and aggregate the review scores, exclude target column \"price\"\nnumeric_cols = [x.name for x in airbnb_df.schema.fields if (x.dataType == DoubleType()) and (x.name != \"price\")]\n\n@feature_table\ndef select_numeric_features(data):\n    return data.select([\"index\"] + numeric_cols)\n\nnumeric_features_df = select_numeric_features(airbnb_df)\ndisplay(numeric_features_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a65a6086-5235-41d0-9469-05a61420e27e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["fs.create_table(\n    name=table_name,\n    primary_keys=[\"index\"],\n    df=numeric_features_df,\n    schema=numeric_features_df.schema,\n    description=\"Numeric features of airbnb data\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"231c5b35-77f2-4464-a5b7-e36af302a0db"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Alternatively, you can **`create_table`** with schema only (without **`df`**), and populate data to the feature table with **`fs.write_table`**. **`fs.write_table`** supports both **`overwrite`** and **`merge`** modes.\n\nExample:\n\n**`\nfs.create_table(\n    name=table_name,\n    primary_keys=[\"index\"],\n    schema=numeric_features_df.schema,\n    description=\"Original Airbnb data\"\n)\nfs.write_table(\n    name=table_name,\n    df=numeric_features_df,\n    mode=\"overwrite\"\n)\n`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69e0f78f-47d8-4bb3-b819-549ab78f2c2f"}}},{"cell_type":"markdown","source":["Now let's explore the UI and see how it tracks the tables that we created. Navigate to the UI by first ensuring that you are in the Machine Learning workspace, and then clicking on the Feature Store icon on the bottom-left of the navigation bar.\n\n\n<img src=\"https://files.training.databricks.com/images/mlflow/FS_Nav.png\" alt=\"step12\" width=\"150\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"783a952e-39be-43be-94e7-49a3e18839a5"}}},{"cell_type":"markdown","source":["In this screenshot, we can see the feature table that we created.\n<br>\n<br>\nNote the section of **`Producers`**. This section indicates which notebook produces the feature table.\n<br>\n<br>\n<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/mlflow/fs_details+(1).png\" alt=\"step12\" width=\"1000\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d45c39e5-4eb5-40a8-80ae-9252ebf8fb85"}}},{"cell_type":"markdown","source":["We can also look at the metadata of the feature store via the FeatureStore client by using **`get_table()`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"400b5531-c08f-425c-a422-996dbb0ae729"}}},{"cell_type":"code","source":["fs.get_table(table_name).path_data_sources"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"708e1853-cf3e-4c77-9dd8-eb73fb885cf7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["fs.get_table(table_name).description"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc4b847f-b1eb-4370-9a6b-39bf79efb6c2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Train a model with feature store"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7556cd4a-6e81-4f4c-8931-94f868bcd3f0"}}},{"cell_type":"markdown","source":["The prediction target **`price`** should NOT BE included as a feature in the registered feature table.\n\nFurther, there may be other information that _can_ be supplied at inference time, but does not make sense to consider a feature to _look up_. \n\nIn this (fictional) example, we made up a feature **`score_diff_from_last_month`**. It is a feature generated at inference time and used in training as well."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41f88715-37d2-4b23-8b41-93273ee73b63"}}},{"cell_type":"code","source":["## inference data -- index (key), price (target) and a online feature (make up a fictional column - diff of review score in a month) \ninference_data_df = airbnb_df.select(\"index\", \"price\", (rand() * 0.5-0.25).alias(\"score_diff_from_last_month\"))\ndisplay(inference_data_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1816f4ba-6967-48a0-aac2-3cff63e2373e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Build a training dataset that will use the indicated \"key\" to lookup features from the feature table and also the online feature **`score_diff_from_last_month`**. We will use <a href=\"https://docs.databricks.com/dev-tools/api/python/latest/feature-store/databricks.feature_store.entities.feature_lookup.html\" target=\"_blank\">FeatureLookup</a> and if you specify no features, it will return all of them except the primary key."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5569bef-8c9e-42fd-9221-11f8d51a4970"}}},{"cell_type":"code","source":["def load_data(table_name, lookup_key):\n    model_feature_lookups = [FeatureLookup(table_name=table_name, lookup_key=lookup_key)]\n\n    # fs.create_training_set will look up features in model_feature_lookups with matched key from inference_data_df\n    training_set = fs.create_training_set(inference_data_df, model_feature_lookups, label=\"price\", exclude_columns=\"index\")\n    training_pd = training_set.load_df().toPandas()\n\n    # Create train and test datasets\n    X = training_pd.drop(\"price\", axis=1)\n    y = training_pd[\"price\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, X_test, y_train, y_test, training_set\n\nX_train, X_test, y_train, y_test, training_set = load_data(table_name, \"index\")\nX_train.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f9a0ceb-3110-46e5-92f5-334baefbdf14"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Train a **RandomForestRegressor** model and log the model with the Feature Store. An MLflow run is started to track the autologged components as well as the Feature Store logged model. However, we will disable the MLflow model autologging as the model will be explicitly logged via the Feature Store.\n\nNOTE: This is an overly simplistic example, used solely for demo purposes."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4a2be23-717b-4c2e-be98-8deded0c4c8d"}}},{"cell_type":"code","source":["from mlflow.tracking.client import MlflowClient\n\nclient = MlflowClient()\n\ntry:\n    client.delete_registered_model(f\"feature_store_airbnb_{cleaned_username}\") # Deleting model if already created\nexcept:\n    None"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e97da397-99bb-4489-a54f-c9019d0cc774"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Disable model autologging and instead log explicitly via the FeatureStore\nmlflow.sklearn.autolog(log_models=False)\n\ndef train_model(X_train, X_test, y_train, y_test, training_set, fs):\n    ## fit and log model\n    with mlflow.start_run() as run:\n\n        rf = RandomForestRegressor(max_depth=3, n_estimators=20, random_state=42)\n        rf.fit(X_train, y_train)\n        y_pred = rf.predict(X_test)\n\n        mlflow.log_metric(\"test_mse\", mean_squared_error(y_test, y_pred))\n        mlflow.log_metric(\"test_r2_score\", r2_score(y_test, y_pred))\n\n        fs.log_model(\n            model=rf,\n            artifact_path=\"feature-store-model\",\n            flavor=mlflow.sklearn,\n            training_set=training_set,\n            registered_model_name=f\"feature_store_airbnb_{cleaned_username}\",\n            input_example=X_train[:5],\n            signature=infer_signature(X_train, y_train)\n        )\n\ntrain_model(X_train, X_test, y_train, y_test, training_set, fs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5c77ee4-3840-4b30-a968-f80a934d52a4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now, view the run from MLflow UI. You can find the model parameters logged with MLflow autolog.\n<br>\n<br>\n<img src=\"https://files.training.databricks.com/images/mlflow/fs_log_model_mlflow_params.png\" alt=\"step12\" width=\"1000\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29aea9a4-9e14-4a13-8673-e09e60a47491"}}},{"cell_type":"markdown","source":["In addition, note the artifacts saved for the run, it saves two model artifacts:\n - **model** : raw sklearn flavor model - logged from mlflow autolog\n - **feature_store_model** : packaged feature store model that can be used directly for batch scoring - logged from **`fs.log_model`**\n<br>\n<br>\n\n<img src=\"https://files.training.databricks.com/images/301/updated_feature_store_9_1.png\" alt=\"step12\" width=\"1000\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14d4515b-5545-4cd7-bddf-a207685db010"}}},{"cell_type":"markdown","source":["The **`feature_store_model`** is registered in the MLflow model registry as well. You can find it in **`Models`** page. It is also logged at the feature store page, indicating which features in the feature table are used for the model. We will exam feature/model lineage through the UI together later."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ee649c4-748d-4945-b416-2d76c9586c17"}}},{"cell_type":"markdown","source":["### Feature Store Batch Scoring\n\nApply a feature store registered MLflow model to features with **`score_batch`**. Input data only need the key column **`index`** and online feature **`score_diff_from_last_month`**. Everything else is looked up."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc14d6fe-1f63-43f5-9451-685306f5230e"}}},{"cell_type":"code","source":["## For sake of simplicity, we will just predict on the same inference_data_df\nbatch_input_df = inference_data_df.drop(\"price\") # Exclude true label\npredictions_df = fs.score_batch(f\"models:/feature_store_airbnb_{cleaned_username}/1\", \n                                  batch_input_df, result_type=\"double\")\ndisplay(predictions_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c354588-31ee-4f0f-bb16-f2dafb5923f7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Overwrite feature table\nLastly, we'll condense some of the review columns and update the feature table: we'll do this by calculating the average review score for each listing."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b256872f-3d68-49f7-8cda-851ce1da046b"}}},{"cell_type":"code","source":["## select numeric features and aggregate the review scores\nreview_columns = [\"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \n                 \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\"]\n@feature_table\ndef select_numeric_features(data):\n    result = (data.select([\"index\"] + numeric_cols)\n              .withColumn(\"average_review_score\", expr(\"+\".join(review_columns)) / lit(len(review_columns)))\n              .drop(*review_columns)\n             )\n    return result\n\ncondensed_review_df = select_numeric_features(airbnb_df)\ndisplay(condensed_review_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d7bc02a-7443-4615-a428-27382a0189ae"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's now drop those features using **`overwrite`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d92cc43-c9d0-425b-99f9-6eb47e90c0aa"}}},{"cell_type":"code","source":["fs.write_table(\n    name=table_name,\n    df=condensed_review_df,\n    mode=\"overwrite\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b4e530a-1d26-4384-99e4-835b2ba9a689"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Explore the feature permission, lineage and freshness from Feature Store UI"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d91e0aee-4fb4-478e-b924-edfec01d1b93"}}},{"cell_type":"markdown","source":["On the UI, we can see that:\n- A new column has been added to the feature list;\n- Columns that we deleted are also still present. However, the deleted features will have **`null`** as their values when we read in the table;\n- The \"Models\" column are populated, listing models use the features from the table\n- The last column **`Notebooks`** are populated. This column indicates which notebooks consume the features in the feature table.\n\n<img src=\"https://files.training.databricks.com/images/mlflow/feature_store_list.png\" alt=\"step12\" width=\"800\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc0b0285-d445-4840-8646-4f65ac9be30a"}}},{"cell_type":"markdown","source":["Now, let's read in the feature data from the Feature Store. By default, **`fs.read_table()`** reads in the latest version of the feature table. To read in the specific version of feature table, you can optionally specify the argument **`as_of_delta_timestamp`** by passing a date in a timestamp format or string.\n\n\nNote that the values of the deleted columns have been replaced by **`null`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14084e97-98df-4767-9c96-ab9e2cb2d7ea"}}},{"cell_type":"code","source":["# Displays most recent table\ndisplay(fs.read_table(name=table_name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fac449c-ac89-4557-a81f-92867428c835"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["If you need to use the features for real-time serving, you can publish your features to an <a href=\"https://docs.databricks.com/applications/machine-learning/feature-store.html#publish-features-to-an-online-feature-store\" target=\"_blank\">online store</a>.\n\nWe can perform control who has permissions to the feature table on the UI.\n\nTo delete the table, use the **`delete`** button on the UI. **You need to delete the delta table from database as well.**\n<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/mlflow/fs_permissions+(1).png\" alt=\"step12\" width=\"700\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9934e2e1-7b4a-41ab-b8d1-5556b418f68c"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72c33aa7-964d-4ac3-8f26-832a19824020"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 10 - Feature Store","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157726716}},"nbformat":4,"nbformat_minor":0}
