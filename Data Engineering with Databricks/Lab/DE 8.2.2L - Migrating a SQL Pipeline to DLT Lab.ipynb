{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f3305b1-ba7a-4608-ab58-1d43aace7a8d"}}},{"cell_type":"markdown","source":["# Lab: Migrating a SQL Pipeline to Delta Live Tables\n\nThis notebook will be completed by you to implement a DLT pipeline using SQL. \n\nIt is **not intended** to be executed interactively, but rather to be deployed as a pipeline once you have completed your changes.\n\nTo aid in completion of this Notebook, please refer to the <a href=\"https://docs.databricks.com/data-engineering/delta-live-tables/delta-live-tables-language-ref.html#sql\" target=\"_blank\">DLT syntax documentation</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96fc5449-bad8-4461-9305-e80774527a5a"}}},{"cell_type":"markdown","source":["## Declare Bronze Table\n\nDeclare a bronze table that ingests JSON data incrementally (using Auto Loader) from the simulated cloud source. The source location is already supplied as an argument; using this value is illustrated in the cell below.\n\nAs we did previously, include two additional columns:\n* **`receipt_time`** that records a timestamp as returned by **`current_timestamp()`** \n* **`source_file`** that is obtained by **`input_file_name()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3fac5e3-f83c-4076-a7c7-1775e07c78e4"}}},{"cell_type":"code","source":["%sql\n-- TODO\nCREATE or refresh streaming live table recordings_bronze\nAS SELECT current_timestamp() receipt_time, input_file_name() source_file, *\n  FROM cloud_files(\"${source}\", \"json\", map(\"cloudFiles.schemaHints\", \"time DOUBLE\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58369ad5-9611-4b01-bc1e-8218b98d0042"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table."]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"message","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>message</th></tr></thead><tbody><tr><td>This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table.</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### PII File\n\nUsing a similar CTAS syntax, create a live **table** into the CSV data found at */mnt/training/healthcare/patient*.\n\nTo properly configure Auto Loader for this source, you will need to specify the following additional parameters:\n\n| option | value |\n| --- | --- |\n| **`header`** | **`true`** |\n| **`cloudFiles.inferColumnTypes`** | **`true`** |\n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"/> Auto Loader configurations for CSV can be found <a href=\"https://docs.databricks.com/spark/latest/structured-streaming/auto-loader-csv.html\" target=\"_blank\">here</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4bec9e3e-6570-43f3-ab80-93cafca3bce5"}}},{"cell_type":"code","source":["%sql\n-- ANSWER\nCREATE OR REFRESH STREAMING LIVE TABLE pii\nAS SELECT *\n  FROM cloud_files(\"/mnt/training/healthcare/patient\", \"csv\", map(\"header\", \"true\", \"cloudFiles.inferColumnTypes\", \"true\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"602b257a-1f18-444b-878c-6b3673103b27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table."]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"message","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>message</th></tr></thead><tbody><tr><td>This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table.</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Declare Silver Tables\n\nOur silver table, **`recordings_parsed`**, will consist of the following fields:\n\n| Field | Type |\n| --- | --- |\n| **`device_id`** | **`INTEGER`** |\n| **`mrn`** | **`LONG`** |\n| **`heartrate`** | **`DOUBLE`** |\n| **`time`** | **`TIMESTAMP`** (example provided below) |\n| **`name`** | **`STRING`** |\n\nThis query should also enrich the data through an inner join with the **`pii`** table on the common **`mrn`** field to obtain the name.\n\nImplement quality control by applying a constraint to drop records with an invalid **`heartrate`** (that is, not greater than zero)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7b3075b-90bd-4752-b2da-db263488916e"}}},{"cell_type":"code","source":["%sql\n-- ANSWER\n\nCREATE OR REFRESH STREAMING LIVE TABLE recordings_enriched\n  (CONSTRAINT positive_heartrate EXPECT (heartrate > 0) ON VIOLATION DROP ROW)\nAS SELECT \n  CAST(a.device_id AS INTEGER) device_id, \n  CAST(a.mrn AS LONG) mrn, \n  CAST(a.heartrate AS DOUBLE) heartrate, \n  CAST(from_unixtime(a.time, 'yyyy-MM-dd HH:mm:ss') AS TIMESTAMP) time,\n  b.name\n  FROM STREAM(live.recordings_bronze) a\n  INNER JOIN STREAM(live.pii) b\n  ON a.mrn = b.mrn"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d058b13-7f67-4151-97c4-9737f9c1608c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table."]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"message","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>message</th></tr></thead><tbody><tr><td>This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table.</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Gold Table\n\nCreate a gold table, **`daily_patient_avg`**, that aggregates **`recordings_enriched`** by **`mrn`**, **`name`**, and **`date`** and delivers the following columns:\n\n| Column name | Value |\n| --- | --- |\n| **`mrn`** | **`mrn`** from source |\n| **`name`** | **`name`** from source |\n| **`avg_heartrate`** | Average **`heartrate`** from the grouping |\n| **`date`** | Date extracted from **`time`** |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a750d7fb-d9fc-46fd-8395-299eb8908d8e"}}},{"cell_type":"code","source":["%sql\n-- ANSWER\n\nCREATE OR REFRESH STREAMING LIVE TABLE daily_patient_avg\n  COMMENT \"Daily mean heartrates by patient\"\n  AS SELECT mrn, name, MEAN(heartrate) avg_heartrate, DATE(time) `date`\n    FROM STREAM(live.recordings_enriched)\n    GROUP BY mrn, name, DATE(time)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3319da9c-3cdd-4986-b1ef-f41b05f522c6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table."]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"message","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>message</th></tr></thead><tbody><tr><td>This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table.</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee0d6382-ae73-4dc7-b3d5-c487a48b4cc0"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 8.2.2L - Migrating a SQL Pipeline to DLT Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2331746562403081}},"nbformat":4,"nbformat_minor":0}
