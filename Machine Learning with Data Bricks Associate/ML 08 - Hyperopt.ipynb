{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8afefbb7-3d23-4808-92f7-9ef9021d0066"}}},{"cell_type":"markdown","source":["# Hyperopt\n\n- **Hyperopt is a Python library for \"serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions\"**.\n\n- In the machine learning workflow, hyperopt can be used to **distribute/parallelize the hyperparameter optimization process with more advanced optimization strategies than are available in other libraries**.\n\nThere are two ways to **scale hyperopt with Apache Spark**:\n* **Use single-machine hyperopt with a distributed training algorithm (e.g. MLlib)**\n* **Use distributed hyperopt with single-machine training algorithms (e.g. scikit-learn) with the SparkTrials class.** \n\n- In this lesson, **we will use single-machine hyperopt with MLlib**, but in the lab, you will see **how to use hyperopt to distribute the hyperparameter tuning of single node models**. \n\n- **Unfortunately you canâ€™t use hyperopt to distribute the hyperparameter optimization for distributed training algorithms at this time. However, you do still get the benefit of using more advanced hyperparameter search algorthims (random search, TPE, etc.) with Spark ML.**\n\n\nResources:\n\n0. <a href=\"http://hyperopt.github.io/hyperopt/scaleout/spark/\" target=\"_blank\">Documentation</a>\n0. <a href=\"https://docs.databricks.com/applications/machine-learning/automl/hyperopt/index.html\" target=\"_blank\">Hyperopt on Databricks</a>\n0. <a href=\"https://databricks.com/blog/2019/06/07/hyperparameter-tuning-with-mlflow-apache-spark-mllib-and-hyperopt.html\" target=\"_blank\">Hyperparameter Tuning with MLflow, Apache Spark MLlib and Hyperopt</a>\n0. <a href=\"https://databricks.com/blog/2021/04/15/how-not-to-tune-your-model-with-hyperopt.html\" target=\"_blank\">How (Not) to Tune Your Model With Hyperopt</a>\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - **Use hyperopt to find the optimal parameters for an MLlib model using TPE**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"491cfcdf-d187-4881-9cec-f25310f1d66e"}}},{"cell_type":"code","source":["%pip install mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fefb732b-aee1-4da0-9e65-0a487a8abeb5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /databricks/python3/lib/python3.8/site-packages (1.28.0)\nRequirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.1.0)\nRequirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.17.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (8.1.3)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nRequirement already satisfied: docker&lt;6,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (5.0.3)\nRequirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.4.2)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nRequirement already satisfied: prometheus-flask-exporter&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.20.3)\nRequirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (6.0)\nRequirement already satisfied: alembic&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.8.1)\nRequirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.1.27)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nRequirement already satisfied: sqlalchemy&lt;2,&gt;=1.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.4.40)\nRequirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.1.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (4.12.0)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nRequirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.2.2)\nRequirement already satisfied: querystring-parser&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: importlib-resources in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (5.9.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (1.2.1)\nRequirement already satisfied: oauthlib&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (3.2.0)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nRequirement already satisfied: pyjwt&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (2.4.0)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (0.8.10)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;6,&gt;=4.0.0-&gt;mlflow) (1.4.0)\nRequirement already satisfied: itsdangerous&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (2.1.2)\nRequirement already satisfied: Jinja2&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (3.1.2)\nRequirement already satisfied: Werkzeug&gt;=2.2.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (2.2.2)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (4.0.9)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (5.0.0)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0-&gt;mlflow) (3.8.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&gt;=3.0-&gt;Flask&lt;3-&gt;mlflow) (2.1.1)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22-&gt;mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2-&gt;mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter&lt;1-&gt;mlflow) (0.10.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (4.0.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.8/site-packages (from sqlalchemy&lt;2,&gt;=1.4.0-&gt;mlflow) (1.1.3)\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /databricks/python3/lib/python3.8/site-packages (1.28.0)\nRequirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.1.0)\nRequirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.17.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (8.1.3)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nRequirement already satisfied: docker&lt;6,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (5.0.3)\nRequirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.4.2)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nRequirement already satisfied: prometheus-flask-exporter&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.20.3)\nRequirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (6.0)\nRequirement already satisfied: alembic&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.8.1)\nRequirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.1.27)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nRequirement already satisfied: sqlalchemy&lt;2,&gt;=1.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.4.40)\nRequirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.1.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (4.12.0)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nRequirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.2.2)\nRequirement already satisfied: querystring-parser&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: importlib-resources in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (5.9.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (1.2.1)\nRequirement already satisfied: oauthlib&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (3.2.0)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nRequirement already satisfied: pyjwt&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (2.4.0)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (0.8.10)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;6,&gt;=4.0.0-&gt;mlflow) (1.4.0)\nRequirement already satisfied: itsdangerous&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (2.1.2)\nRequirement already satisfied: Jinja2&gt;=3.0 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (3.1.2)\nRequirement already satisfied: Werkzeug&gt;=2.2.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (2.2.2)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (4.0.9)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (5.0.0)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;5,&gt;=3.7.0-&gt;mlflow) (3.8.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&gt;=3.0-&gt;Flask&lt;3-&gt;mlflow) (2.1.1)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&lt;22-&gt;mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2-&gt;mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter&lt;1-&gt;mlflow) (0.10.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (4.0.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.8/site-packages (from sqlalchemy&lt;2,&gt;=1.4.0-&gt;mlflow) (1.1.3)\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33680bab-73b1-47b4-87ab-97a8da5c27e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Defining courseware-specific utility methods...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Defining courseware-specific utility methods..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">The source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/scalable-machine-learning-with-apache-spark/v01/\n\nYour dataset directory is\ndbfs:/user/manujkumar.joshi@celebaltech.com/dbacademy/machine_learning/datasets\n\nSkipping install of existing dataset.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/scalable-machine-learning-with-apache-spark/v01/\n\nYour dataset directory is\ndbfs:/user/manujkumar.joshi@celebaltech.com/dbacademy/machine_learning/datasets\n\nSkipping install of existing dataset.\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's start by loading in our SF Airbnb Dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"827043b7-5e15-440a-83fe-26f74d084ad2"}}},{"cell_type":"code","source":["file_path = f\"{datasets_dir}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\nairbnb_df = spark.read.format(\"delta\").load(file_path)\ntrain_df, val_df, test_df = airbnb_df.randomSplit([.6, .2, .2], seed=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e491b861-ace4-4ebe-9ae9-9750a8708eed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### We will then create our random forest pipeline and regression evaluator.\n- **StringIndexer**: StringIndexer encodes a string column of labels to a column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fb42e58-e763-4ff9-9d40-4f9511f27abf"}}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\ncategorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\nindex_output_cols = [x + \"Index\" for x in categorical_cols]\n\nstring_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n\nnumeric_cols = [field for (field, dataType) in train_df.dtypes if ((dataType == \"double\") & (field != \"price\"))]\nassembler_inputs = index_output_cols + numeric_cols\nvec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n\nrf = RandomForestRegressor(labelCol=\"price\", maxBins=40, seed=42)\npipeline = Pipeline(stages=[string_indexer, vec_assembler, rf])\nregression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cb96de1-187a-4151-bf8b-ac411af17868"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Next, we get to the hyperopt-specific part of the workflow.\n\nFirst, we define our **objective function**. The objective function has two primary requirements:\n\n1. An **input** **`params`** including hyperparameter values to use when training the model\n2. An **output** containing a loss metric on which to optimize\n\nIn this case, we are specifying values of **`max_depth`** and **`num_trees`** and returning the RMSE as our loss metric.\n\nWe are reconstructing our pipeline for the **`RandomForestRegressor`** to use the specified hyperparameter values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebeae4ff-925a-49bd-b754-3863cbea7c04"}}},{"cell_type":"code","source":["def objective_function(params):    \n    # set the hyperparameters that we want to tune\n    max_depth = params[\"max_depth\"]\n    num_trees = params[\"num_trees\"]\n\n    with mlflow.start_run():\n        estimator = pipeline.copy({rf.maxDepth: max_depth, rf.numTrees: num_trees})\n        model = estimator.fit(train_df)\n\n        preds = model.transform(val_df)\n        rmse = regression_evaluator.evaluate(preds)\n        mlflow.log_metric(\"rmse\", rmse)\n\n    return rmse"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5dabd075-ef2f-4a2c-8561-0b4d7929c792"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Next, we define our search space. \n\nThis is similar to the parameter grid in a grid search process. However, we are only specifying the range of values rather than the individual, specific values to be tested. It's up to hyperopt's optimization algorithm to choose the actual values.\n\nSee the <a href=\"https://github.com/hyperopt/hyperopt/wiki/FMin\" target=\"_blank\">documentation</a> for helpful tips on defining your search space."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be27f658-a113-4ede-8ffb-15e9b89781f0"}}},{"cell_type":"code","source":["# %pip install hyperopt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8359575d-7b22-4e45-8394-b32ced541600"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from hyperopt import hp\n\nsearch_space = {\n    \"max_depth\": hp.quniform(\"max_depth\", 2, 5, 1),\n    \"num_trees\": hp.quniform(\"num_trees\", 10, 100, 1)\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbe2c5d2-1853-4c0d-aaef-4f33af644329"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["- **`fmin()`** generates new hyperparameter configurations to use for your **`objective_function`**. It will evaluate 4 models in total, using the information from the previous models to make a more informative decision for the the next hyperparameter to try. \n\n- Hyperopt allows for parallel hyperparameter tuning using either random search or Tree of Parzen Estimators (TPE). Note that in the cell below, we are importing **`tpe`**. According to the <a href=\"http://hyperopt.github.io/hyperopt/scaleout/spark/\" target=\"_blank\">documentation</a>, TPE is an adaptive algorithm that \n\n> iteratively explores the hyperparameter space. Each new hyperparameter setting tested will be chosen based on previous results. \n\n- Hence, **`tpe.suggest`** is a Bayesian method.\n\n- MLflow also integrates with Hyperopt, so you can track the results of all the models youâ€™ve trained and their results as part of your hyperparameter tuning. Notice you can track the MLflow experiment in this notebook, but you can also specify an external experiment."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9e74866-2240-4485-aece-f22d8a825326"}}},{"cell_type":"code","source":["from hyperopt import fmin, tpe, Trials\nimport numpy as np\nimport mlflow\nimport mlflow.spark\nmlflow.pyspark.ml.autolog(log_models=False)\n\nnum_evals = 4\ntrials = Trials()\nbest_hyperparam = fmin(fn=objective_function, \n                       space=search_space,\n                       algo=tpe.suggest, \n                       max_evals=num_evals,\n                       trials=trials,\n                       rstate=np.random.default_rng(42))\n\n# Retrain model on train & validation dataset and evaluate on test dataset\nwith mlflow.start_run():\n    best_max_depth = best_hyperparam[\"max_depth\"]\n    best_num_trees = best_hyperparam[\"num_trees\"]\n    estimator = pipeline.copy({rf.maxDepth: best_max_depth, rf.numTrees: best_num_trees})\n    combined_df = train_df.union(val_df) # Combine train & validation together\n\n    pipeline_model = estimator.fit(combined_df)\n    pred_df = pipeline_model.transform(test_df)\n    rmse = regression_evaluator.evaluate(pred_df)\n\n    # Log param and metrics for the final model\n    mlflow.log_param(\"maxDepth\", best_max_depth)\n    mlflow.log_param(\"numTrees\", best_num_trees)\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.spark.log_model(pipeline_model, \"model\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81d0d2b0-b241-46ab-84d9-80d48a5f3151"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\r  0%|          | 0/4 [00:00&lt;?, ?trial/s, best loss=?]\r                                                     \r2022/08/27 05:03:29 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r  0%|          | 0/4 [00:01&lt;?, ?trial/s, best loss=?]\r 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:27&lt;01:23, 27.84s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:03:56 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:28&lt;01:23, 27.84s/trial, best loss: 357.82375290612674]\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:32&lt;00:28, 14.46s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:04:01 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:33&lt;00:28, 14.46s/trial, best loss: 357.82375290612674]\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:37&lt;00:10, 10.09s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:04:06 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:38&lt;00:10, 10.09s/trial, best loss: 357.82375290612674]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42&lt;00:00,  7.87s/trial, best loss: 357.82375290612674]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42&lt;00:00, 10.57s/trial, best loss: 357.82375290612674]\n2022/08/27 05:04:11 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/4 [00:00&lt;?, ?trial/s, best loss=?]\r                                                     \r2022/08/27 05:03:29 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r  0%|          | 0/4 [00:01&lt;?, ?trial/s, best loss=?]\r 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:27&lt;01:23, 27.84s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:03:56 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:28&lt;01:23, 27.84s/trial, best loss: 357.82375290612674]\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:32&lt;00:28, 14.46s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:04:01 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:33&lt;00:28, 14.46s/trial, best loss: 357.82375290612674]\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:37&lt;00:10, 10.09s/trial, best loss: 357.82375290612674]\r                                                                               \r2022/08/27 05:04:06 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n\n\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:38&lt;00:10, 10.09s/trial, best loss: 357.82375290612674]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42&lt;00:00,  7.87s/trial, best loss: 357.82375290612674]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42&lt;00:00, 10.57s/trial, best loss: 357.82375290612674]\n2022/08/27 05:04:11 WARNING mlflow.utils: Truncated the value of the key `VectorAssembler.inputCols`. Truncated value: `[&#39;host_is_superhostIndex&#39;, &#39;cancellation_policyIndex&#39;, &#39;instant_bookableIndex&#39;, &#39;neighbourhood_cleansedIndex&#39;, &#39;property_typeIndex&#39;, &#39;room_typeIndex&#39;, &#39;bed_typeIndex&#39;, &#39;host_total_listings_count&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;accommodates&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;beds&#39;, &#39;minimum_nights&#39;, &#39;number_of_reviews&#39;, &#39;review_scores_rating&#39;, &#39;review_scores_accuracy&#39;, &#39;review_scores_cleanliness&#39;, &#39;review_scores_checkin&#39;, &#39;review_scores_communication&#39;, &#39;review_scores_location&#39;, &#39;review_scores_value&#39;, &#39;be...`\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2903f8e0-6aee-4b6e-92ae-82ce15fcebe2"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 08 - Hyperopt","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2051889157728035}},"nbformat":4,"nbformat_minor":0}
