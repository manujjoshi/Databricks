{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36206f17-e902-423c-b195-1fa317d5039e"}}},{"cell_type":"markdown","source":["# Partitioning\n##### Objectives\n1. Get partitions and cores\n1. Repartition DataFrames\n1. Configure default shuffle partitions\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a>: `repartition`, `coalesce`, `rdd.getNumPartitions`\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkConf.html?#pyspark.SparkConf\" target=\"_blank\">SparkConf</a>: `get`, `set`\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#spark-session-apis\" target=\"_blank\">SparkSession</a>: `spark.sparkContext.defaultParallelism`\n\n##### SparkConf Parameters\n- `spark.sql.shuffle.partitions`, `spark.sql.adaptive.enabled`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31cc7e53-1f46-4e47-b33b-6e46252086cb"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ffde252-3976-4690-9803-d04815a9ac55"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Get partitions and cores\n\nUse the `rdd` method `getNumPartitions` to get the number of DataFrame partitions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e783d6e6-463e-4645-9384-59ce57b0ee59"}}},{"cell_type":"code","source":["df = spark.read.parquet(eventsPath)\ndf.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4e909e9-5293-469f-8f9a-efccc63fa0bb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Access `SparkContext` through `SparkSession` to get the number of cores or slots.\n\nUse the `defaultParallelism` attribute to get the number of cores in a cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"836998f5-ea0e-436b-af1e-bfcf5cb0c8a0"}}},{"cell_type":"code","source":["print(spark.sparkContext.defaultParallelism)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f0f3b01-d4b0-423a-ae64-b8f67646ca7d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["`SparkContext` is also provided in Databricks notebooks as the variable `sc`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6143a23b-6528-47f3-89a7-ed20fa1e41b3"}}},{"cell_type":"code","source":["print(sc.defaultParallelism)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef1d3712-e819-4b3f-b1a9-2c0ebc398c0e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Repartition DataFrame\n\nThere are two methods available to repartition a DataFrame: `repartition` and `coalesce`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43c97e05-a631-4c26-b3df-71772040bbed"}}},{"cell_type":"markdown","source":["#### `repartition`\nReturns a new DataFrame that has exactly `n` partitions.\n\n- Wide transformation\n- Pro: Evenly balances partition sizes  \n- Con: Requires shuffling all data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4e4d5ee-39d6-4bc5-ae08-bd0a79a5c686"}}},{"cell_type":"code","source":["repartitionedDF = df.repartition(8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4bbac7d-65f3-4abd-81e1-35e8fea5c0f8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["repartitionedDF.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0bb8edc-ddda-4069-977a-9d86fe0a2aa2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### `coalesce`\nReturns a new DataFrame that has exactly `n` partitions, when fewer partitions are requested.\n\nIf a larger number of partitions is requested, it will stay at the current number of partitions.\n\n- Narrow transformation, some partitions are effectively concatenated\n- Pro: Requires no shuffling\n- Cons:\n  - Is not able to increase # partitions\n  - Can result in uneven partition sizes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"114995ad-e1cd-4499-8ffb-0ee818a68390"}}},{"cell_type":"code","source":["coalesceDF = df.coalesce(8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4daa4a8-127b-4287-aeda-02486989190a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["coalesceDF.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7cfcacd-748a-498a-838b-25fc193514f9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Configure default shuffle partitions\n\nUse the SparkSession's `conf` attribute to get and set dynamic Spark configuration properties. The `spark.sql.shuffle.partitions` property determines the number of partitions that result from a shuffle. Let's check its default value:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cab5ee8-6272-4925-948f-4edbaac69598"}}},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"216475cb-5891-4e1a-a098-c4a03c07fccb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Assuming that the data set isn't too large, you could configure the default number of shuffle partitions to match the number of cores:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9bdd950-4ad4-454a-9b08-57931a65bb35"}}},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", spark.sparkContext.defaultParallelism)\nprint(spark.conf.get(\"spark.sql.shuffle.partitions\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ccfad837-ce3f-42f6-926f-75bc0d447939"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Partitioning Guidelines\n- Make the number of partitions a multiple of the number of cores\n- Target a partition size of ~200MB\n- Size default shuffle partitions by dividing largest shuffle stage input by the target partition size (e.g., 4TB / 200MB = 20,000 shuffle partition count)\n\n<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> When writing a DataFrame to storage, the number of DataFrame partitions determines the number of data files written. (This assumes that <a href=\"https://sparkbyexamples.com/apache-hive/hive-partitions-explained-with-examples/\" target=\"_blank\">Hive partitioning</a> is not used for the data in storage. A discussion of DataFrame partitioning vs Hive partitioning is beyond the scope of this class.)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9e3d5b4-1a12-4029-ab37-1a1152e08e0d"}}},{"cell_type":"markdown","source":["### Adaptive Query Execution\n\n<img src=\"https://files.training.databricks.com/images/aspwd/partitioning_aqe.png\" width=\"60%\" />\n\nIn Spark 3, <a href=\"https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution\" target=\"_blank\">AQE</a> is now able to <a href=\"https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html\" target=\"_blank\"> dynamically coalesce shuffle partitions</a> at runtime. This means that you can set `spark.sql.shuffle.partitions` based on the largest data set your application processes and allow AQE to reduce the number of partitions automatically when there is less data to process.\n\nThe `spark.sql.adaptive.enabled` configuration option controls whether AQE is turned on/off."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c8ef9b1-ab8c-4bf7-b5e7-c1ba82a84278"}}},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.adaptive.enabled\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88d43bc3-9ebf-4f02-afe0-79f37369f217"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f44da21-3006-4498-9cf2-8b17edd2a3bb"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a90ecf0c-93b7-436b-b4a8-a85361b6f05f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04913c36-7318-456b-a5a4-467060870bce"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 3.3 - Partitioning","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2331746562399062}},"nbformat":4,"nbformat_minor":0}
